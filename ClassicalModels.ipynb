{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b4dce0",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac159165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "2022-11-07 23:16:31.957291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "import gensim\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10378d58",
   "metadata": {},
   "source": [
    "# 1. Using only title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e385df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>fake</th>\n",
       "      <th>all_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>stopword_count.1</th>\n",
       "      <th>unique_word_count.1</th>\n",
       "      <th>punct_count.1</th>\n",
       "      <th>avg_wordlength.1</th>\n",
       "      <th>avg_sentlength.1</th>\n",
       "      <th>unique_vs_words.1</th>\n",
       "      <th>stopwords_vs_words.1</th>\n",
       "      <th>noun_count.1</th>\n",
       "      <th>adverb_count.1</th>\n",
       "      <th>sentiment_score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>2973</td>\n",
       "      <td>507</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>1968</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>3688</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>2853</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.3052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>2417</td>\n",
       "      <td>431</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  fake                                           all_text  \\\n",
       "0  December 31, 2017     1   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1  December 31, 2017     1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2  December 30, 2017     1   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3  December 29, 2017     1   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4  December 25, 2017     1   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "   char_count  word_count  sent_count  capital_word_count  ...  \\\n",
       "0        2973         507          26                   5  ...   \n",
       "1        1968         313          11                   3  ...   \n",
       "2        3688         595          25                  42  ...   \n",
       "3        2853         458          15                   6  ...   \n",
       "4        2417         431          19                   0  ...   \n",
       "\n",
       "   stopword_count.1  unique_word_count.1  punct_count.1  avg_wordlength.1  \\\n",
       "0                 2                   12              1          6.583333   \n",
       "1                 0                    8              0          8.625000   \n",
       "2                 0                   15              0          6.000000   \n",
       "3                 1                   14              2          5.571429   \n",
       "4                 0                   11              0          6.363636   \n",
       "\n",
       "   avg_sentlength.1  unique_vs_words.1  stopwords_vs_words.1  noun_count.1  \\\n",
       "0              12.0                1.0              0.166667             5   \n",
       "1               8.0                1.0              0.000000             5   \n",
       "2              15.0                1.0              0.000000             7   \n",
       "3              14.0                1.0              0.071429             3   \n",
       "4              11.0                1.0              0.000000             5   \n",
       "\n",
       "   adverb_count.1  sentiment_score.1  \n",
       "0               0            -0.7096  \n",
       "1               0            -0.3400  \n",
       "2               0            -0.2960  \n",
       "3               2            -0.3052  \n",
       "4               1             0.0000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"news_final.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f33566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = news.iloc[:,22:]\n",
    "y_title = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81e4f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count.1</th>\n",
       "      <th>word_count.1</th>\n",
       "      <th>sent_count.1</th>\n",
       "      <th>capital_word_count.1</th>\n",
       "      <th>quoted_word_count.1</th>\n",
       "      <th>stopword_count.1</th>\n",
       "      <th>unique_word_count.1</th>\n",
       "      <th>punct_count.1</th>\n",
       "      <th>avg_wordlength.1</th>\n",
       "      <th>avg_sentlength.1</th>\n",
       "      <th>unique_vs_words.1</th>\n",
       "      <th>stopwords_vs_words.1</th>\n",
       "      <th>noun_count.1</th>\n",
       "      <th>adverb_count.1</th>\n",
       "      <th>sentiment_score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.3052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count.1  word_count.1  sent_count.1  capital_word_count.1  \\\n",
       "0            79            12             1                     0   \n",
       "1            69             8             1                     0   \n",
       "2            90            15             1                     0   \n",
       "3            78            14             1                     1   \n",
       "4            70            11             1                     0   \n",
       "\n",
       "   quoted_word_count.1  stopword_count.1  unique_word_count.1  punct_count.1  \\\n",
       "0                    0                 2                   12              1   \n",
       "1                    0                 0                    8              0   \n",
       "2                    0                 0                   15              0   \n",
       "3                    0                 1                   14              2   \n",
       "4                    0                 0                   11              0   \n",
       "\n",
       "   avg_wordlength.1  avg_sentlength.1  unique_vs_words.1  \\\n",
       "0          6.583333              12.0                1.0   \n",
       "1          8.625000               8.0                1.0   \n",
       "2          6.000000              15.0                1.0   \n",
       "3          5.571429              14.0                1.0   \n",
       "4          6.363636              11.0                1.0   \n",
       "\n",
       "   stopwords_vs_words.1  noun_count.1  adverb_count.1  sentiment_score.1  \n",
       "0              0.166667             5               0            -0.7096  \n",
       "1              0.000000             5               0            -0.3400  \n",
       "2              0.000000             7               0            -0.2960  \n",
       "3              0.071429             3               2            -0.3052  \n",
       "4              0.000000             5               1             0.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de814a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: fake, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5090b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(X_title, y_title, test_size=0.2, shuffle=True, random_state=1) #20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc83258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count.1</th>\n",
       "      <th>word_count.1</th>\n",
       "      <th>sent_count.1</th>\n",
       "      <th>capital_word_count.1</th>\n",
       "      <th>quoted_word_count.1</th>\n",
       "      <th>stopword_count.1</th>\n",
       "      <th>unique_word_count.1</th>\n",
       "      <th>punct_count.1</th>\n",
       "      <th>avg_wordlength.1</th>\n",
       "      <th>avg_sentlength.1</th>\n",
       "      <th>unique_vs_words.1</th>\n",
       "      <th>stopwords_vs_words.1</th>\n",
       "      <th>noun_count.1</th>\n",
       "      <th>adverb_count.1</th>\n",
       "      <th>sentiment_score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24897</th>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11204</th>\n",
       "      <td>127</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>6.047619</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6.230769</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13745</th>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6.058824</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30926 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count.1  word_count.1  sent_count.1  capital_word_count.1  \\\n",
       "24897            71            12             1                     0   \n",
       "3203             72            10             1                     2   \n",
       "11204           127            21             2                     3   \n",
       "4923             81            13             1                     1   \n",
       "13745           103            17             1                     2   \n",
       "...             ...           ...           ...                   ...   \n",
       "7813             93            13             1                     2   \n",
       "32511            61             9             1                     1   \n",
       "5192             80            14             2                     1   \n",
       "12172            71            12             1                     4   \n",
       "33003            63            10             1                     1   \n",
       "\n",
       "       quoted_word_count.1  stopword_count.1  unique_word_count.1  \\\n",
       "24897                    0                 3                   12   \n",
       "3203                     0                 0                   10   \n",
       "11204                    0                 3                   21   \n",
       "4923                     0                 1                   13   \n",
       "13745                    0                 0                   17   \n",
       "...                    ...               ...                  ...   \n",
       "7813                     0                 0                   13   \n",
       "32511                    0                 1                    9   \n",
       "5192                     0                 0                   13   \n",
       "12172                    0                 1                   12   \n",
       "33003                    0                 3                   10   \n",
       "\n",
       "       punct_count.1  avg_wordlength.1  avg_sentlength.1  unique_vs_words.1  \\\n",
       "24897              0          5.916667              12.0           1.000000   \n",
       "3203               1          7.200000              10.0           1.000000   \n",
       "11204              4          6.047619              10.5           1.000000   \n",
       "4923               2          6.230769              13.0           1.000000   \n",
       "13745              2          6.058824              17.0           1.000000   \n",
       "...              ...               ...               ...                ...   \n",
       "7813               4          7.153846              13.0           1.000000   \n",
       "32511              2          6.777778               9.0           1.000000   \n",
       "5192               2          5.714286               7.0           0.928571   \n",
       "12172              2          5.916667              12.0           1.000000   \n",
       "33003              2          6.300000              10.0           1.000000   \n",
       "\n",
       "       stopwords_vs_words.1  noun_count.1  adverb_count.1  sentiment_score.1  \n",
       "24897              0.250000             4               0             0.6712  \n",
       "3203               0.000000             3               0             0.0000  \n",
       "11204              0.142857            11               1             0.5613  \n",
       "4923               0.076923             4               1            -0.2839  \n",
       "13745              0.000000             7               0            -0.8056  \n",
       "...                     ...           ...             ...                ...  \n",
       "7813               0.000000             7               0             0.2023  \n",
       "32511              0.111111             2               0            -0.7184  \n",
       "5192               0.000000             5               0            -0.2481  \n",
       "12172              0.083333             7               2            -0.8868  \n",
       "33003              0.300000             2               0            -0.3612  \n",
       "\n",
       "[30926 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a28f8",
   "metadata": {},
   "source": [
    "### 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515ee8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "lr_clf_title = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "lr_cv_results_title = cross_validate(lr_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be10e3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10956407, 0.13104796, 0.12002802, 0.12128282, 0.11683202,\n",
       "        0.10311985, 0.13740802, 0.118788  , 0.15726995, 0.11859393]),\n",
       " 'score_time': array([0.00426197, 0.00252509, 0.00262785, 0.00336313, 0.00304484,\n",
       "        0.00273633, 0.00237989, 0.00288916, 0.00256801, 0.00481296]),\n",
       " 'test_score': array([0.94002586, 0.94794698, 0.94406725, 0.94148076, 0.94180407,\n",
       "        0.94358228, 0.94115745, 0.94228904, 0.94083414, 0.9442289 ]),\n",
       " 'train_score': array([0.9434519 , 0.94135004, 0.94232013, 0.94320938, 0.94288601,\n",
       "        0.94211803, 0.94316896, 0.94292643, 0.94292643, 0.94236055])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf0cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.12339346408843994\n",
      "Time for scoring classifier on the validation set: 0.0031209230422973634\n",
      "Accuracy of Train: 0.9426717865804365\n",
      "Accuracy of Validation: 0.9427416747494343\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397e736",
   "metadata": {},
   "source": [
    "### 1.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f6a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "gnb_clf_title = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results_title = cross_validate(gnb_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e7d0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01744699, 0.01634002, 0.01584888, 0.01616716, 0.01607275,\n",
       "        0.01513195, 0.0158689 , 0.01524997, 0.01603484, 0.01409793]),\n",
       " 'score_time': array([0.00418305, 0.00316501, 0.00313926, 0.00371003, 0.00355101,\n",
       "        0.00310397, 0.00314498, 0.0031271 , 0.00357699, 0.00303507]),\n",
       " 'test_score': array([0.92935661, 0.93598448, 0.93404462, 0.92870999, 0.92709344,\n",
       "        0.93452958, 0.93178144, 0.93129648, 0.93388296, 0.93614614]),\n",
       " 'train_score': array([0.93298302, 0.93168957, 0.93136621, 0.9327405 , 0.92914309,\n",
       "        0.93168957, 0.93221504, 0.93367017, 0.93229588, 0.93080032])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec1e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.015825939178466798\n",
      "Time for scoring classifier on the validation set: 0.0033736467361450196\n",
      "Accuracy of Train: 0.9318593371059013\n",
      "Accuracy of Validation: 0.9322825735531847\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c938752",
   "metadata": {},
   "source": [
    "### 1.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888434e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results_title = cross_validate(svm_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd046b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.15586686, 4.93490386, 4.89284086, 5.08166814, 5.570925  ,\n",
       "        4.924932  , 4.73700094, 4.98831201, 4.99197102, 5.48028779]),\n",
       " 'score_time': array([2.09188509, 2.14343023, 2.11273813, 2.22617388, 2.187922  ,\n",
       "        2.12133408, 2.10462499, 2.10963011, 2.13526082, 2.26122499]),\n",
       " 'test_score': array([0.94746201, 0.95457485, 0.95489816, 0.95376657, 0.95134174,\n",
       "        0.95279664, 0.9500485 , 0.95085677, 0.95279664, 0.9547365 ]),\n",
       " 'train_score': array([0.95533549, 0.95408246, 0.95347615, 0.95363783, 0.95468876,\n",
       "        0.95412288, 0.95464834, 0.95485044, 0.95444624, 0.95359741])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ddc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 5.075870847702026\n",
      "Time for scoring classifier on the validation set: 2.1494224309921264\n",
      "Accuracy of Train: 0.9542886014551334\n",
      "Accuracy of Validation: 0.9523278370514063\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1693d5",
   "metadata": {},
   "source": [
    "### 1.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eafae87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results_title = cross_validate(rf_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d98b459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.55589485, 1.55726576, 1.57312894, 1.57146525, 1.55644107,\n",
       "        1.55619001, 1.54967117, 1.54060411, 1.53464913, 1.52900696]),\n",
       " 'score_time': array([0.08765221, 0.08809614, 0.08920407, 0.09544969, 0.08715177,\n",
       "        0.08891487, 0.08593011, 0.09585214, 0.08634377, 0.0854249 ]),\n",
       " 'test_score': array([0.94374394, 0.94827029, 0.94616877, 0.94697704, 0.9409958 ,\n",
       "        0.94746201, 0.94390559, 0.94390559, 0.94633042, 0.94616877]),\n",
       " 'train_score': array([0.99882781, 0.99890865, 0.99907033, 0.99882781, 0.99894907,\n",
       "        0.99890865, 0.99866613, 0.99894907, 0.99894907, 0.99882781])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7af292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.5524317264556884\n",
      "Time for scoring classifier on the validation set: 0.08900196552276611\n",
      "Accuracy of Train: 0.9988884397736459\n",
      "Accuracy of Validation: 0.945392822502425\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03253e09",
   "metadata": {},
   "source": [
    "### 1.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfcbfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results_title = cross_validate(xgboost_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f5e2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.01294088, 1.00397491, 1.009022  , 1.039186  , 1.0640769 ,\n",
       "        1.04806495, 1.04679489, 1.01735973, 1.00992894, 1.01108599]),\n",
       " 'score_time': array([0.01553512, 0.01611996, 0.01605201, 0.01606703, 0.01664495,\n",
       "        0.01635098, 0.01595902, 0.015733  , 0.01576424, 0.01590896]),\n",
       " 'test_score': array([0.94519884, 0.95085677, 0.95118008, 0.94988684, 0.94600711,\n",
       "        0.95101843, 0.94843194, 0.94681539, 0.94827029, 0.95053346]),\n",
       " 'train_score': array([0.9525869 , 0.95133387, 0.95161681, 0.95226354, 0.95323363,\n",
       "        0.95153597, 0.95291027, 0.95181892, 0.95157639, 0.95185934])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de8b49ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.02624351978302\n",
      "Time for scoring classifier on the validation set: 0.016013526916503908\n",
      "Accuracy of Train: 0.9520735650767987\n",
      "Accuracy of Validation: 0.9488199159392176\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c454e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_title.loc['Logistic Regression', 'train_acc'] = lr_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'val_acc'] = lr_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'fit_time'] = lr_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Support Vector Machine', 'train_acc'] = svm_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'val_acc'] = svm_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'fit_time'] = svm_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Random Forest', 'train_acc'] = rf_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Random Forest', 'val_acc'] = rf_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Random Forest', 'fit_time'] = rf_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['XGBoost', 'train_acc'] = xgboost_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['XGBoost', 'val_acc'] = xgboost_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['XGBoost', 'fit_time'] = xgboost_cv_results_title[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "104dcb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.942672</td>\n",
       "      <td>0.942742</td>\n",
       "      <td>0.123393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.931859</td>\n",
       "      <td>0.932283</td>\n",
       "      <td>0.015826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.954289</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>5.075871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998888</td>\n",
       "      <td>0.945393</td>\n",
       "      <td>1.552432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.948820</td>\n",
       "      <td>1.026244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc   val_acc  fit_time\n",
       "Logistic Regression      0.942672  0.942742  0.123393\n",
       "Gaussian Naive Bayes     0.931859  0.932283  0.015826\n",
       "Support Vector Machine   0.954289  0.952328  5.075871\n",
       "Random Forest            0.998888  0.945393  1.552432\n",
       "XGBoost                  0.952074  0.948820  1.026244"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a78ee8",
   "metadata": {},
   "source": [
    "# 2. Using All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "898ac5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2973</td>\n",
       "      <td>507</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>282</td>\n",
       "      <td>122</td>\n",
       "      <td>5.863905</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.556213</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>116</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1968</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>209</td>\n",
       "      <td>39</td>\n",
       "      <td>6.287540</td>\n",
       "      <td>28.454545</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>0.383387</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.7685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3688</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>344</td>\n",
       "      <td>148</td>\n",
       "      <td>6.198319</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>167</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2853</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>278</td>\n",
       "      <td>120</td>\n",
       "      <td>6.229258</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>0.606987</td>\n",
       "      <td>0.358079</td>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.9269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2417</td>\n",
       "      <td>431</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>244</td>\n",
       "      <td>40</td>\n",
       "      <td>5.607889</td>\n",
       "      <td>22.684211</td>\n",
       "      <td>0.566125</td>\n",
       "      <td>0.457077</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38653</th>\n",
       "      <td>2862</td>\n",
       "      <td>472</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>270</td>\n",
       "      <td>72</td>\n",
       "      <td>6.063559</td>\n",
       "      <td>31.466667</td>\n",
       "      <td>0.572034</td>\n",
       "      <td>0.387712</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38654</th>\n",
       "      <td>834</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>6.465116</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38655</th>\n",
       "      <td>1982</td>\n",
       "      <td>324</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>219</td>\n",
       "      <td>45</td>\n",
       "      <td>6.117284</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38656</th>\n",
       "      <td>1242</td>\n",
       "      <td>211</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>142</td>\n",
       "      <td>18</td>\n",
       "      <td>5.886256</td>\n",
       "      <td>26.375000</td>\n",
       "      <td>0.672986</td>\n",
       "      <td>0.393365</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38657</th>\n",
       "      <td>1371</td>\n",
       "      <td>216</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>145</td>\n",
       "      <td>29</td>\n",
       "      <td>6.347222</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38658 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count  word_count  sent_count  capital_word_count  \\\n",
       "0            2973         507          26                   5   \n",
       "1            1968         313          11                   3   \n",
       "2            3688         595          25                  42   \n",
       "3            2853         458          15                   6   \n",
       "4            2417         431          19                   0   \n",
       "...           ...         ...         ...                 ...   \n",
       "38653        2862         472          15                  16   \n",
       "38654         834         129           6                   0   \n",
       "38655        1982         324          16                   4   \n",
       "38656        1242         211           8                   0   \n",
       "38657        1371         216           9                   2   \n",
       "\n",
       "       quoted_word_count  stopword_count  unique_word_count  punct_count  \\\n",
       "0                      0             195                282          122   \n",
       "1                      0             120                209           39   \n",
       "2                      0             220                344          148   \n",
       "3                      0             164                278          120   \n",
       "4                      0             197                244           40   \n",
       "...                  ...             ...                ...          ...   \n",
       "38653                  0             183                270           72   \n",
       "38654                  0              46                 81           15   \n",
       "38655                  0             133                219           45   \n",
       "38656                  0              83                142           18   \n",
       "38657                  0              68                145           29   \n",
       "\n",
       "       avg_wordlength  avg_sentlength  unique_vs_words  stopwords_vs_words  \\\n",
       "0            5.863905       19.500000         0.556213            0.384615   \n",
       "1            6.287540       28.454545         0.667732            0.383387   \n",
       "2            6.198319       23.800000         0.578151            0.369748   \n",
       "3            6.229258       30.533333         0.606987            0.358079   \n",
       "4            5.607889       22.684211         0.566125            0.457077   \n",
       "...               ...             ...              ...                 ...   \n",
       "38653        6.063559       31.466667         0.572034            0.387712   \n",
       "38654        6.465116       21.500000         0.627907            0.356589   \n",
       "38655        6.117284       20.250000         0.675926            0.410494   \n",
       "38656        5.886256       26.375000         0.672986            0.393365   \n",
       "38657        6.347222       24.000000         0.671296            0.314815   \n",
       "\n",
       "       noun_count  adverb_count  sentiment_score  \n",
       "0             116            36          -0.9139  \n",
       "1              94            10          -0.7685  \n",
       "2             167            20          -0.9955  \n",
       "3             143            24          -0.9269  \n",
       "4              79            16           0.3134  \n",
       "...           ...           ...              ...  \n",
       "38653         100            18           0.1181  \n",
       "38654          36             1           0.5423  \n",
       "38655          74            15           0.9818  \n",
       "38656          53             8           0.8100  \n",
       "38657          61             6           0.6908  \n",
       "\n",
       "[38658 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.iloc[:,6:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "227fbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news.iloc[:,6:21]\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d71baddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2973</td>\n",
       "      <td>507</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>282</td>\n",
       "      <td>122</td>\n",
       "      <td>5.863905</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.556213</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>116</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1968</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>209</td>\n",
       "      <td>39</td>\n",
       "      <td>6.287540</td>\n",
       "      <td>28.454545</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>0.383387</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.7685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3688</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>344</td>\n",
       "      <td>148</td>\n",
       "      <td>6.198319</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>167</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2853</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>278</td>\n",
       "      <td>120</td>\n",
       "      <td>6.229258</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>0.606987</td>\n",
       "      <td>0.358079</td>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.9269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2417</td>\n",
       "      <td>431</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>244</td>\n",
       "      <td>40</td>\n",
       "      <td>5.607889</td>\n",
       "      <td>22.684211</td>\n",
       "      <td>0.566125</td>\n",
       "      <td>0.457077</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  sent_count  capital_word_count  quoted_word_count  \\\n",
       "0        2973         507          26                   5                  0   \n",
       "1        1968         313          11                   3                  0   \n",
       "2        3688         595          25                  42                  0   \n",
       "3        2853         458          15                   6                  0   \n",
       "4        2417         431          19                   0                  0   \n",
       "\n",
       "   stopword_count  unique_word_count  punct_count  avg_wordlength  \\\n",
       "0             195                282          122        5.863905   \n",
       "1             120                209           39        6.287540   \n",
       "2             220                344          148        6.198319   \n",
       "3             164                278          120        6.229258   \n",
       "4             197                244           40        5.607889   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  stopwords_vs_words  noun_count  \\\n",
       "0       19.500000         0.556213            0.384615         116   \n",
       "1       28.454545         0.667732            0.383387          94   \n",
       "2       23.800000         0.578151            0.369748         167   \n",
       "3       30.533333         0.606987            0.358079         143   \n",
       "4       22.684211         0.566125            0.457077          79   \n",
       "\n",
       "   adverb_count  sentiment_score  \n",
       "0            36          -0.9139  \n",
       "1            10          -0.7685  \n",
       "2            20          -0.9955  \n",
       "3            24          -0.9269  \n",
       "4            16           0.3134  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91d376ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1570504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24897</th>\n",
       "      <td>388</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>4029</td>\n",
       "      <td>672</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>355</td>\n",
       "      <td>60</td>\n",
       "      <td>5.995536</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.528274</td>\n",
       "      <td>0.434524</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>0.9835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11204</th>\n",
       "      <td>684</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>97</td>\n",
       "      <td>10</td>\n",
       "      <td>5.652893</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.413223</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>1958</td>\n",
       "      <td>338</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>210</td>\n",
       "      <td>52</td>\n",
       "      <td>5.792899</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>0.621302</td>\n",
       "      <td>0.431953</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>0.9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13745</th>\n",
       "      <td>759</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>111</td>\n",
       "      <td>12</td>\n",
       "      <td>5.580882</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.360294</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.9586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>2051</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>230</td>\n",
       "      <td>53</td>\n",
       "      <td>6.159159</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>0.690691</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.9874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>2766</td>\n",
       "      <td>446</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>248</td>\n",
       "      <td>46</td>\n",
       "      <td>6.201794</td>\n",
       "      <td>27.875000</td>\n",
       "      <td>0.556054</td>\n",
       "      <td>0.354260</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.9948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>2204</td>\n",
       "      <td>379</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>239</td>\n",
       "      <td>53</td>\n",
       "      <td>5.815303</td>\n",
       "      <td>21.055556</td>\n",
       "      <td>0.630607</td>\n",
       "      <td>0.408971</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>188</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.9158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>1852</td>\n",
       "      <td>309</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>171</td>\n",
       "      <td>41</td>\n",
       "      <td>5.993528</td>\n",
       "      <td>28.090909</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.362460</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.9900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30926 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count  word_count  sent_count  capital_word_count  \\\n",
       "24897         388          60           2                   2   \n",
       "3203         4029         672          21                  10   \n",
       "11204         684         121           5                   4   \n",
       "4923         1958         338           8                   9   \n",
       "13745         759         136           9                   8   \n",
       "...           ...         ...         ...                 ...   \n",
       "7813         2051         333          12                   4   \n",
       "32511        2766         446          16                   9   \n",
       "5192         2204         379          18                   4   \n",
       "12172         188          32           1                   4   \n",
       "33003        1852         309          11                   5   \n",
       "\n",
       "       quoted_word_count  stopword_count  unique_word_count  punct_count  \\\n",
       "24897                  0              21                 50            9   \n",
       "3203                   0             292                355           60   \n",
       "11204                  0              50                 97           10   \n",
       "4923                   0             146                210           52   \n",
       "13745                  0              49                111           12   \n",
       "...                  ...             ...                ...          ...   \n",
       "7813                   0             124                230           53   \n",
       "32511                  0             158                248           46   \n",
       "5192                   0             155                239           53   \n",
       "12172                  0              10                 29            4   \n",
       "33003                  0             112                171           41   \n",
       "\n",
       "       avg_wordlength  avg_sentlength  unique_vs_words  stopwords_vs_words  \\\n",
       "24897        6.466667       30.000000         0.833333            0.350000   \n",
       "3203         5.995536       32.000000         0.528274            0.434524   \n",
       "11204        5.652893       24.200000         0.801653            0.413223   \n",
       "4923         5.792899       42.250000         0.621302            0.431953   \n",
       "13745        5.580882       15.111111         0.816176            0.360294   \n",
       "...               ...             ...              ...                 ...   \n",
       "7813         6.159159       27.750000         0.690691            0.372372   \n",
       "32511        6.201794       27.875000         0.556054            0.354260   \n",
       "5192         5.815303       21.055556         0.630607            0.408971   \n",
       "12172        5.875000       32.000000         0.906250            0.312500   \n",
       "33003        5.993528       28.090909         0.553398            0.362460   \n",
       "\n",
       "       noun_count  adverb_count  sentiment_score  \n",
       "24897          24             0           0.5998  \n",
       "3203          119            35           0.9835  \n",
       "11204          33             8           0.2115  \n",
       "4923           77            21           0.9372  \n",
       "13745          28             6          -0.9586  \n",
       "...           ...           ...              ...  \n",
       "7813           88            15          -0.9874  \n",
       "32511          83            12          -0.9948  \n",
       "5192           90            25          -0.8496  \n",
       "12172          12             2          -0.9158  \n",
       "33003          70             4          -0.9900  \n",
       "\n",
       "[30926 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30c0c1",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba763afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "lr_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "lr_cv_results = cross_validate(lr_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed16f26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.18553591, 0.13649297, 0.15314579, 0.19910407, 0.19980502,\n",
       "        0.14530277, 0.15596223, 0.15047193, 0.14731598, 0.13826108]),\n",
       " 'score_time': array([0.00323319, 0.0022459 , 0.00270414, 0.0031538 , 0.00246787,\n",
       "        0.00220013, 0.00283694, 0.00213623, 0.0039928 , 0.00223374]),\n",
       " 'test_score': array([0.86129971, 0.85693501, 0.8533786 , 0.86663434, 0.86420951,\n",
       "        0.8580666 , 0.85984481, 0.86744261, 0.85305529, 0.86372454]),\n",
       " 'train_score': array([0.86046888, 0.85877122, 0.86176233, 0.8589329 , 0.85856912,\n",
       "        0.86046888, 0.85957963, 0.85711399, 0.86228779, 0.85877122])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "043d0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.16113977432250975\n",
      "Time for scoring classifier on the validation set: 0.002720475196838379\n",
      "Accuracy of Train: 0.8596725949878741\n",
      "Accuracy of Validation: 0.8604591011962496\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93026ee",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e12d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "gnb_clf = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results = cross_validate(gnb_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "467e09d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01778293, 0.01438904, 0.01378512, 0.01367092, 0.01359987,\n",
       "        0.01472998, 0.01488709, 0.01321816, 0.01357913, 0.01368022]),\n",
       " 'score_time': array([0.00385213, 0.00310993, 0.00271392, 0.0027101 , 0.00315213,\n",
       "        0.00301695, 0.00277901, 0.00335503, 0.00272083, 0.00300789]),\n",
       " 'test_score': array([0.69915939, 0.70400905, 0.68913676, 0.68461041, 0.6933398 ,\n",
       "        0.68962173, 0.69689622, 0.6962496 , 0.6871969 , 0.69608794]),\n",
       " 'train_score': array([0.69122878, 0.70145513, 0.68823767, 0.68864188, 0.68569119,\n",
       "        0.69409863, 0.69090542, 0.69664511, 0.69353274, 0.68755053])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b37876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.014332246780395509\n",
      "Time for scoring classifier on the validation set: 0.003041791915893555\n",
      "Accuracy of Train: 0.6917987065481003\n",
      "Accuracy of Validation: 0.6936307791787908\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d0d9d",
   "metadata": {},
   "source": [
    "### 2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff5c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results = cross_validate(svm_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d177485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([10.00752306,  9.34740496,  9.70486617,  9.93004894,  9.77530003,\n",
       "         9.73726916,  9.63809204,  9.92612028,  9.60106301,  9.88994002]),\n",
       " 'score_time': array([4.22620487, 4.52214408, 4.42038178, 4.2963028 , 4.29424596,\n",
       "        4.26841068, 4.39200711, 4.32460904, 4.24389887, 4.37176991]),\n",
       " 'test_score': array([0.90413838, 0.90171355, 0.90268348, 0.90656321, 0.90753314,\n",
       "        0.90462334, 0.90413838, 0.909473  , 0.89896541, 0.91189783]),\n",
       " 'train_score': array([0.90909458, 0.90901374, 0.90788197, 0.90743735, 0.90800323,\n",
       "        0.90763945, 0.90747777, 0.90739693, 0.90978173, 0.90541633])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7ed3408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 9.755762767791747\n",
      "Time for scoring classifier on the validation set: 4.33599750995636\n",
      "Accuracy of Train: 0.907914308811641\n",
      "Accuracy of Validation: 0.9051729712253476\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78295a",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66ec0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results = cross_validate(rf_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85398c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.41825294, 4.24330592, 7.33296013, 6.20008397, 4.1168108 ,\n",
       "        4.11707306, 4.03921294, 4.12423921, 4.45252609, 4.2229929 ]),\n",
       " 'score_time': array([0.09921002, 0.09949589, 0.21579909, 0.18955207, 0.10087442,\n",
       "        0.09975696, 0.09940505, 0.12335706, 0.10380816, 0.10418487]),\n",
       " 'test_score': array([0.90139024, 0.90058196, 0.90203686, 0.90446169, 0.904785  ,\n",
       "        0.90397672, 0.90543162, 0.90575493, 0.89993534, 0.91319108]),\n",
       " 'train_score': array([1.        , 0.99995958, 0.99995958, 1.        , 0.99995958,\n",
       "        0.99995958, 1.        , 1.        , 1.        , 1.        ])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "873fa289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 4.7267457962036135\n",
      "Time for scoring classifier on the validation set: 0.12354435920715331\n",
      "Accuracy of Train: 0.9999838318512531\n",
      "Accuracy of Validation: 0.9041545425153572\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab04d68",
   "metadata": {},
   "source": [
    "### 2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c2ce94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results = cross_validate(xgboost_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0d0e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.49273109, 1.45524716, 1.43584776, 1.43139195, 1.53374696,\n",
       "        1.54018903, 1.50560474, 1.45626497, 1.46508861, 1.43000889]),\n",
       " 'score_time': array([0.01912498, 0.01792908, 0.0176332 , 0.01773   , 0.0179038 ,\n",
       "        0.01771498, 0.01789212, 0.01853895, 0.01717925, 0.01804709]),\n",
       " 'test_score': array([0.89104429, 0.89185257, 0.89395409, 0.89945037, 0.8942774 ,\n",
       "        0.89460071, 0.89476237, 0.90074361, 0.89314581, 0.90607824]),\n",
       " 'train_score': array([0.90626516, 0.90505255, 0.90412288, 0.90307195, 0.90493129,\n",
       "        0.90323363, 0.90388036, 0.90254648, 0.9041633 , 0.90194018])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "744454c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.4746121168136597\n",
      "Time for scoring classifier on the validation set: 0.017969346046447753\n",
      "Accuracy of Train: 0.9039207760711401\n",
      "Accuracy of Validation: 0.8959909473003556\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1db7b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_text = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_all_text.loc['Logistic Regression', 'train_acc'] = lr_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'val_acc'] = lr_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'fit_time'] = lr_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Support Vector Machine', 'train_acc'] = svm_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'val_acc'] = svm_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'fit_time'] = svm_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Random Forest', 'train_acc'] = rf_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'val_acc'] = rf_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'fit_time'] = rf_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['XGBoost', 'train_acc'] = xgboost_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'val_acc'] = xgboost_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'fit_time'] = xgboost_cv_results[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b4e4782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.859673</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.161140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.691799</td>\n",
       "      <td>0.693631</td>\n",
       "      <td>0.014332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.907914</td>\n",
       "      <td>0.905173</td>\n",
       "      <td>9.755763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.904155</td>\n",
       "      <td>4.726746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.903921</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>1.474612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc   val_acc  fit_time\n",
       "Logistic Regression      0.859673  0.860459  0.161140\n",
       "Gaussian Naive Bayes     0.691799  0.693631  0.014332\n",
       "Support Vector Machine   0.907914  0.905173  9.755763\n",
       "Random Forest            0.999984  0.904155  4.726746\n",
       "XGBoost                  0.903921  0.895991  1.474612"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d778f6e",
   "metadata": {},
   "source": [
    "# 3. Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b8c8471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4bbde\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Title Only</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4bbde_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_4bbde_level0_col1\" class=\"col_heading level0 col1\" >val_acc</th>\n",
       "      <th id=\"T_4bbde_level0_col2\" class=\"col_heading level0 col2\" >fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbde_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_4bbde_row0_col0\" class=\"data row0 col0\" >0.942672</td>\n",
       "      <td id=\"T_4bbde_row0_col1\" class=\"data row0 col1\" >0.942742</td>\n",
       "      <td id=\"T_4bbde_row0_col2\" class=\"data row0 col2\" >0.123393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbde_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_4bbde_row1_col0\" class=\"data row1 col0\" >0.931859</td>\n",
       "      <td id=\"T_4bbde_row1_col1\" class=\"data row1 col1\" >0.932283</td>\n",
       "      <td id=\"T_4bbde_row1_col2\" class=\"data row1 col2\" >0.015826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbde_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_4bbde_row2_col0\" class=\"data row2 col0\" >0.954289</td>\n",
       "      <td id=\"T_4bbde_row2_col1\" class=\"data row2 col1\" >0.952328</td>\n",
       "      <td id=\"T_4bbde_row2_col2\" class=\"data row2 col2\" >5.075871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbde_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_4bbde_row3_col0\" class=\"data row3 col0\" >0.998888</td>\n",
       "      <td id=\"T_4bbde_row3_col1\" class=\"data row3 col1\" >0.945393</td>\n",
       "      <td id=\"T_4bbde_row3_col2\" class=\"data row3 col2\" >1.552432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbde_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_4bbde_row4_col0\" class=\"data row4 col0\" >0.952074</td>\n",
       "      <td id=\"T_4bbde_row4_col1\" class=\"data row4 col1\" >0.948820</td>\n",
       "      <td id=\"T_4bbde_row4_col2\" class=\"data row4 col2\" >1.026244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_455ea\" style='display:inline'>\n",
       "  <caption>Title & Text</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_455ea_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_455ea_level0_col1\" class=\"col_heading level0 col1\" >val_acc</th>\n",
       "      <th id=\"T_455ea_level0_col2\" class=\"col_heading level0 col2\" >fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_455ea_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_455ea_row0_col0\" class=\"data row0 col0\" >0.859673</td>\n",
       "      <td id=\"T_455ea_row0_col1\" class=\"data row0 col1\" >0.860459</td>\n",
       "      <td id=\"T_455ea_row0_col2\" class=\"data row0 col2\" >0.161140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_455ea_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_455ea_row1_col0\" class=\"data row1 col0\" >0.691799</td>\n",
       "      <td id=\"T_455ea_row1_col1\" class=\"data row1 col1\" >0.693631</td>\n",
       "      <td id=\"T_455ea_row1_col2\" class=\"data row1 col2\" >0.014332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_455ea_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_455ea_row2_col0\" class=\"data row2 col0\" >0.907914</td>\n",
       "      <td id=\"T_455ea_row2_col1\" class=\"data row2 col1\" >0.905173</td>\n",
       "      <td id=\"T_455ea_row2_col2\" class=\"data row2 col2\" >9.755763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_455ea_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_455ea_row3_col0\" class=\"data row3 col0\" >0.999984</td>\n",
       "      <td id=\"T_455ea_row3_col1\" class=\"data row3 col1\" >0.904155</td>\n",
       "      <td id=\"T_455ea_row3_col2\" class=\"data row3 col2\" >4.726746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_455ea_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_455ea_row4_col0\" class=\"data row4 col0\" >0.903921</td>\n",
       "      <td id=\"T_455ea_row4_col1\" class=\"data row4 col1\" >0.895991</td>\n",
       "      <td id=\"T_455ea_row4_col2\" class=\"data row4 col2\" >1.474612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html \n",
    "\n",
    "results_title_style = results_title.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_text.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbbacd",
   "metadata": {},
   "source": [
    "1. SVM takes the longest to fit across both experiments\n",
    "2. For title only, although SVM performed the best, XGBoost wasn't far off in terms of validation accuracy and took 6.5 times less to fit\n",
    "3. For all text, although SVM performed the best, the long fitting time dissauades us from using it, instead XGBoost or even Random Forest would be a better choice\n",
    "4. On average, validation accuracy for title is higher than that of all text, hence we could say that we are able to predict if an article is real based on the title alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c8b5c",
   "metadata": {},
   "source": [
    "# 4. Test Accuracy - Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7a7e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f83470e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.942896</td>\n",
       "      <td>0.945292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.931773</td>\n",
       "      <td>0.930031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.954116</td>\n",
       "      <td>0.953440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998739</td>\n",
       "      <td>0.945163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.951303</td>\n",
       "      <td>0.949302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc  test_acc\n",
       "Logistic Regression      0.942896  0.945292\n",
       "Gaussian Naive Bayes     0.931773  0.930031\n",
       "Support Vector Machine   0.954116  0.953440\n",
       "Random Forest            0.998739  0.945163\n",
       "XGBoost                  0.951303  0.949302"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_title = sklearn.base.clone(lr_clf_title)\n",
    "lr_clf_title.fit(X_train_title, y_train_title)\n",
    "lr_clf_title_train_acc = lr_clf_title.score(X_train_title, y_train_title)\n",
    "lr_clf_title_test_acc = lr_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Logistic Regression', 'train_acc'] = lr_clf_title_train_acc\n",
    "results_title_final.loc['Logistic Regression', 'test_acc'] = lr_clf_title_test_acc\n",
    "\n",
    "gnb_clf_title = sklearn.base.clone(gnb_clf_title)\n",
    "gnb_clf_title.fit(X_train_title, y_train_title)\n",
    "gnb_clf_title_train_acc = gnb_clf_title.score(X_train_title, y_train_title)\n",
    "gnb_clf_title_test_acc = gnb_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_clf_title_train_acc\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_clf_title_test_acc\n",
    "\n",
    "svm_clf_title = sklearn.base.clone(svm_clf_title)\n",
    "svm_clf_title.fit(X_train_title, y_train_title)\n",
    "svm_clf_title_train_acc = svm_clf_title.score(X_train_title, y_train_title)\n",
    "svm_clf_title_test_acc = svm_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Support Vector Machine', 'train_acc'] = svm_clf_title_train_acc\n",
    "results_title_final.loc['Support Vector Machine', 'test_acc'] = svm_clf_title_test_acc\n",
    "\n",
    "rf_clf_title = sklearn.base.clone(rf_clf_title)\n",
    "rf_clf_title.fit(X_train_title, y_train_title)\n",
    "rf_clf_title_train_acc = rf_clf_title.score(X_train_title, y_train_title)\n",
    "rf_clf_title_test_acc = rf_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Random Forest', 'train_acc'] = rf_clf_title_train_acc\n",
    "results_title_final.loc['Random Forest', 'test_acc'] = rf_clf_title_test_acc\n",
    "\n",
    "xgboost_clf_title = sklearn.base.clone(xgboost_clf_title)\n",
    "xgboost_clf_title.fit(X_train_title, y_train_title)\n",
    "xgboost_clf_title_train_acc = xgboost_clf_title.score(X_train_title, y_train_title)\n",
    "xgboost_clf_title_test_acc = xgboost_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['XGBoost', 'train_acc'] = xgboost_clf_title_train_acc\n",
    "results_title_final.loc['XGBoost', 'test_acc'] = xgboost_clf_title_test_acc\n",
    "\n",
    "results_title_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df65dd",
   "metadata": {},
   "source": [
    "# 5. Test Accuracy - Title + Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09fae308",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "636a5f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.859891</td>\n",
       "      <td>0.850362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.689614</td>\n",
       "      <td>0.696198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.908491</td>\n",
       "      <td>0.896793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.903673</td>\n",
       "      <td>0.886834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc  test_acc\n",
       "Logistic Regression      0.859891  0.850362\n",
       "Gaussian Naive Bayes     0.689614  0.696198\n",
       "Support Vector Machine   0.908491  0.896793\n",
       "Random Forest            1.000000  0.900802\n",
       "XGBoost                  0.903673  0.886834"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = sklearn.base.clone(lr_clf)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_all_train_acc = lr_clf.score(X_train, y_train)\n",
    "lr_all_test_acc = lr_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Logistic Regression', 'train_acc'] = lr_all_train_acc\n",
    "results_all_final.loc['Logistic Regression', 'test_acc'] = lr_all_test_acc\n",
    "\n",
    "gnb_clf = sklearn.base.clone(gnb_clf)\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_all_train_acc = gnb_clf.score(X_train, y_train)\n",
    "gnb_all_test_acc = gnb_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_all_train_acc\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_all_test_acc\n",
    "\n",
    "svm_clf = sklearn.base.clone(svm_clf)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_all_train_acc = svm_clf.score(X_train, y_train)\n",
    "svm_all_test_acc = svm_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Support Vector Machine', 'train_acc'] = svm_all_train_acc\n",
    "results_all_final.loc['Support Vector Machine', 'test_acc'] = svm_all_test_acc\n",
    "\n",
    "rf_clf = sklearn.base.clone(rf_clf)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_all_train_acc = rf_clf.score(X_train, y_train)\n",
    "rf_all_test_acc = rf_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Random Forest', 'train_acc'] = rf_all_train_acc\n",
    "results_all_final.loc['Random Forest', 'test_acc'] = rf_all_test_acc\n",
    "\n",
    "xgboost_clf = sklearn.base.clone(xgboost_clf)\n",
    "xgboost_clf.fit(X_train, y_train)\n",
    "xgboost_all_train_acc = xgboost_clf.score(X_train, y_train)\n",
    "xgboost_all_test_acc = xgboost_clf.score(X_test, y_test)\n",
    "results_all_final.loc['XGBoost', 'train_acc'] = xgboost_all_train_acc\n",
    "results_all_final.loc['XGBoost', 'test_acc'] = xgboost_all_test_acc\n",
    "\n",
    "results_all_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7fdfef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3c88b\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Title Only</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3c88b_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_3c88b_level0_col1\" class=\"col_heading level0 col1\" >test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3c88b_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_3c88b_row0_col0\" class=\"data row0 col0\" >0.942896</td>\n",
       "      <td id=\"T_3c88b_row0_col1\" class=\"data row0 col1\" >0.945292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c88b_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_3c88b_row1_col0\" class=\"data row1 col0\" >0.931773</td>\n",
       "      <td id=\"T_3c88b_row1_col1\" class=\"data row1 col1\" >0.930031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c88b_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_3c88b_row2_col0\" class=\"data row2 col0\" >0.954116</td>\n",
       "      <td id=\"T_3c88b_row2_col1\" class=\"data row2 col1\" >0.953440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c88b_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_3c88b_row3_col0\" class=\"data row3 col0\" >0.998739</td>\n",
       "      <td id=\"T_3c88b_row3_col1\" class=\"data row3 col1\" >0.945163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c88b_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_3c88b_row4_col0\" class=\"data row4 col0\" >0.951303</td>\n",
       "      <td id=\"T_3c88b_row4_col1\" class=\"data row4 col1\" >0.949302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_30932\" style='display:inline'>\n",
       "  <caption>Title & Text</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_30932_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_30932_level0_col1\" class=\"col_heading level0 col1\" >test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_30932_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_30932_row0_col0\" class=\"data row0 col0\" >0.859891</td>\n",
       "      <td id=\"T_30932_row0_col1\" class=\"data row0 col1\" >0.850362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30932_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_30932_row1_col0\" class=\"data row1 col0\" >0.689614</td>\n",
       "      <td id=\"T_30932_row1_col1\" class=\"data row1 col1\" >0.696198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30932_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_30932_row2_col0\" class=\"data row2 col0\" >0.908491</td>\n",
       "      <td id=\"T_30932_row2_col1\" class=\"data row2 col1\" >0.896793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30932_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_30932_row3_col0\" class=\"data row3 col0\" >1.000000</td>\n",
       "      <td id=\"T_30932_row3_col1\" class=\"data row3 col1\" >0.900802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30932_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_30932_row4_col0\" class=\"data row4 col0\" >0.903673</td>\n",
       "      <td id=\"T_30932_row4_col1\" class=\"data row4 col1\" >0.886834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_title_style = results_title_final.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_final.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc0534",
   "metadata": {
    "id": "1d6c2549"
   },
   "source": [
    "# Using All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88940c26",
   "metadata": {
    "id": "ca6bdbc9"
   },
   "outputs": [],
   "source": [
    "X = news['all_text']\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1a7aa2d",
   "metadata": {
    "id": "5df3c627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: all_text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8de8d51",
   "metadata": {
    "id": "67a86a1e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7e1dd98",
   "metadata": {
    "id": "DKLXJF36ixTI"
   },
   "outputs": [],
   "source": [
    "# Converting text to vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorization = TfidfVectorizer()\n",
    "X_train_vec = vectorization.fit_transform(X_train)\n",
    "X_test_vec = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa9ca0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a083475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train: 0.9833473452758197\n",
      "Accuracy of Test: 0.9776254526642525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(random_state=1)\n",
    "GBC.fit(X_train_vec, y_train)\n",
    "\n",
    "print(f'Accuracy of Train: {GBC.score(X_train_vec, y_train)}')\n",
    "print(f'Accuracy of Test: {GBC.score(X_test_vec, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19941b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_vec, y_train)\n",
    "nlp_results['LR'] = [LR.score(X_train_vec, y_train), LR.score(X_test_vec, y_test)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3af3e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB().fit(X_train_vec, y_train)\n",
    "nlp_results['NB']= [NB.score(X_train_vec, y_train), NB.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7105e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM.fit(X_train_vec, y_train)\n",
    "nlp_results['SVM']= [SVM.score(X_train_vec, y_train), SVM.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8fc8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9884563150746944, 0.9811174340403518], 'NB': [0.9457737825777662, 0.9372736678737713], 'SVM': [0.99899760719136, 0.987325400931195], 'RFC': [1.0, 0.9714174857734093]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(random_state=1)\n",
    "RFC.fit(X_train_vec, y_train)\n",
    "\n",
    "nlp_results['RFC']= [RFC.score(X_train_vec, y_train), RFC.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d2aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGB = XGBClassifier(random_state=1)\n",
    "XGB.fit(X_train_vec, y_train)\n",
    "nlp_results['XGB'] = [XGB.score(X_train_vec, y_train), XGB.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34dfe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RFC': [1.0, 0.9714174857734093], 'XGB': [1.0, 0.987842731505432], 'LR': [0.9884563150746944, 0.9811174340403518], 'NB': [0.9457737825777662, 0.9372736678737713], 'SVM': [0.99899760719136, 0.987325400931195]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d5836",
   "metadata": {},
   "source": [
    "### Results for all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99590ab1",
   "metadata": {
    "id": "c8833b85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.981117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.945774</td>\n",
       "      <td>0.937274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.987325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc\n",
       "Logistic Regression       0.988456  0.981117\n",
       "Multinomial Naive Bayes   0.945774  0.937274\n",
       "Support Vector Machine    0.998998  0.987325\n",
       "Random Forest             1.000000  0.971417\n",
       "XGBoost                   1.000000  0.987843"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_results_all_text = pd.DataFrame()\n",
    "\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'train_acc'] = nlp_results['LR'][0]\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'test_acc'] = nlp_results['LR'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results['NB'][0]\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results['NB'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'train_acc'] = nlp_results['SVM'][0]\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'test_acc'] = nlp_results['SVM'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Random Forest', 'train_acc'] = nlp_results['RFC'][0]\n",
    "tfidf_results_all_text.loc['Random Forest', 'test_acc'] = nlp_results['RFC'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['XGBoost', 'train_acc'] = nlp_results['XGB'][0]\n",
    "tfidf_results_all_text.loc['XGBoost', 'test_acc'] = nlp_results['XGB'][1]\n",
    "tfidf_results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afad7a",
   "metadata": {
    "id": "c4ed466d"
   },
   "source": [
    "# Using only title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07fd7b54",
   "metadata": {
    "id": "c291759a"
   },
   "outputs": [],
   "source": [
    "X2 = news['title']\n",
    "y2 = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcb528e1",
   "metadata": {
    "id": "c7d9e9e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6174e141",
   "metadata": {
    "id": "cefe6309"
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a2e9297",
   "metadata": {
    "id": "Z2WUUtNmjd3w"
   },
   "outputs": [],
   "source": [
    "# Converting text to vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorization2 = TfidfVectorizer()\n",
    "X_train_vec2 = vectorization2.fit_transform(X_train2)\n",
    "X_test_vec2 = vectorization2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc933b94",
   "metadata": {
    "id": "2gUk5E5yhKxc"
   },
   "outputs": [],
   "source": [
    "nlp_results_title = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18f38bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = LogisticRegression()\n",
    "LR2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['LR'] = [LR2.score(X_train_vec2, y_train2), LR2.score(X_test_vec2, y_test2)] \n",
    "\n",
    "NB2 = MultinomialNB().fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['NB']= [NB2.score(X_train_vec2, y_train2), NB2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56ef1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC2 = RandomForestClassifier(random_state=1)\n",
    "RFC2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['RFC']= [RFC2.score(X_train_vec2, y_train2), RFC2.score(X_test_vec2, y_test2)]\n",
    "\n",
    "XGB2 = XGBClassifier(random_state=1)\n",
    "XGB2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['XGB'] = [XGB2.score(X_train_vec2, y_train2), XGB2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61e10b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM2 = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['SVM']= [SVM2.score(X_train_vec2, y_train2), SVM2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac66823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9650779279570588, 0.9443869632695292], 'NB': [0.957964172540904, 0.9408949818934299], 'RFC': [1.0, 0.9425763062596999], 'XGB': [0.9040613076375865, 0.8936885669943093], 'SVM': [0.9959904287654401, 0.9511122607346094]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991a816",
   "metadata": {},
   "source": [
    "### Results for title only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3875a0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.965078</td>\n",
       "      <td>0.944387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.940895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.951112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.904061</td>\n",
       "      <td>0.893689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc\n",
       "Logistic Regression       0.965078  0.944387\n",
       "Multinomial Naive Bayes   0.957964  0.940895\n",
       "Support Vector Machine    0.995990  0.951112\n",
       "Random Forest             1.000000  0.942576\n",
       "XGBoost                   0.904061  0.893689"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_results_title = pd.DataFrame()\n",
    "\n",
    "tfidf_results_title.loc['Logistic Regression', 'train_acc'] = nlp_results_title['LR'][0]\n",
    "tfidf_results_title.loc['Logistic Regression', 'test_acc'] = nlp_results_title['LR'][1]\n",
    "\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results_title['NB'][0]\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results_title['NB'][1]\n",
    "\n",
    "tfidf_results_title.loc['Support Vector Machine', 'train_acc'] = nlp_results_title['SVM'][0]\n",
    "tfidf_results_title.loc['Support Vector Machine', 'test_acc'] = nlp_results_title['SVM'][1]\n",
    "\n",
    "tfidf_results_title.loc['Random Forest', 'train_acc'] = nlp_results_title['RFC'][0]\n",
    "tfidf_results_title.loc['Random Forest', 'test_acc'] = nlp_results_title['RFC'][1]\n",
    "\n",
    "tfidf_results_title.loc['XGBoost', 'train_acc'] = nlp_results_title['XGB'][0]\n",
    "tfidf_results_title.loc['XGBoost', 'test_acc'] = nlp_results_title['XGB'][1]\n",
    "tfidf_results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb88d8",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451ae25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987033547209766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7999999999999999,\n",
       " 'max_depth': 15,\n",
       " 'learning_rate': 0.3,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'colsample_bylevel': 0.7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {'max_depth': [3, 6, 10, 15],\n",
    "      'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "      'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "      }\n",
    "search = RandomizedSearchCV(estimator=XGB,\n",
    "                         param_distributions=params,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=2, random_state=1)\n",
    "search.fit(X_train_vec, y_train)\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ce11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9879720641489912\n"
     ]
    }
   ],
   "source": [
    "XGB_tuned = XGBClassifier(**search.best_params_, random_state=1)\n",
    "XGB_tuned.fit(X_train_vec, y_train)\n",
    "nlp_results['XGB Tuned'] = [XGB_tuned.score(X_train_vec, y_train), XGB_tuned.score(X_test_vec, y_test)]\n",
    "print(\"Training Accuracy:\", nlp_results['XGB Tuned'][0])\n",
    "print(\"Testing Accuracy:\", nlp_results['XGB Tuned'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d192b",
   "metadata": {},
   "source": [
    "Accuracy went up by a marginal 0.02% after tuning hyperparameters. Hence, hyperparameter tuning may not be worth the efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a6d3a1c9702cbdea61a84eb923333e247e4db67d8a1f6fe21a7310eabf978f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
