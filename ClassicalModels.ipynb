{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c06bffc",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0fcb45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import sklearn\n",
    "\n",
    "# Model Building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d03981",
   "metadata": {},
   "source": [
    "# 1. Title - Metadata & Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0928793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>fake</th>\n",
       "      <th>all_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>stopword_count.1</th>\n",
       "      <th>unique_word_count.1</th>\n",
       "      <th>punct_count.1</th>\n",
       "      <th>avg_wordlength.1</th>\n",
       "      <th>avg_sentlength.1</th>\n",
       "      <th>unique_vs_words.1</th>\n",
       "      <th>stopwords_vs_words.1</th>\n",
       "      <th>noun_count.1</th>\n",
       "      <th>adverb_count.1</th>\n",
       "      <th>sentiment_score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>2973</td>\n",
       "      <td>507</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>1968</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>3688</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>2853</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.3052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>2417</td>\n",
       "      <td>431</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  fake                                           all_text  \\\n",
       "0  December 31, 2017     1   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1  December 31, 2017     1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2  December 30, 2017     1   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3  December 29, 2017     1   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4  December 25, 2017     1   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "   char_count  word_count  sent_count  capital_word_count  ...  \\\n",
       "0        2973         507          26                   5  ...   \n",
       "1        1968         313          11                   3  ...   \n",
       "2        3688         595          25                  42  ...   \n",
       "3        2853         458          15                   6  ...   \n",
       "4        2417         431          19                   0  ...   \n",
       "\n",
       "   stopword_count.1  unique_word_count.1  punct_count.1  avg_wordlength.1  \\\n",
       "0                 2                   12              1          6.583333   \n",
       "1                 0                    8              0          8.625000   \n",
       "2                 0                   15              0          6.000000   \n",
       "3                 1                   14              2          5.571429   \n",
       "4                 0                   11              0          6.363636   \n",
       "\n",
       "   avg_sentlength.1  unique_vs_words.1  stopwords_vs_words.1  noun_count.1  \\\n",
       "0              12.0                1.0              0.166667             5   \n",
       "1               8.0                1.0              0.000000             5   \n",
       "2              15.0                1.0              0.000000             7   \n",
       "3              14.0                1.0              0.071429             3   \n",
       "4              11.0                1.0              0.000000             5   \n",
       "\n",
       "   adverb_count.1  sentiment_score.1  \n",
       "0               0            -0.7096  \n",
       "1               0            -0.3400  \n",
       "2               0            -0.2960  \n",
       "3               2            -0.3052  \n",
       "4               1             0.0000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"news_final.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b35ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = news.iloc[:,22:]\n",
    "y_title = news['fake']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628e9f7",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3acf31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(X_title, y_title, test_size=0.2, shuffle=True, random_state=1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bb181",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159de4b",
   "metadata": {},
   "source": [
    "### 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "029972ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.33 s, sys: 183 ms, total: 4.51 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_clf_title = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "lr_cv_results_title = cross_validate(lr_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "39e37ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.19818497, 0.15242815, 0.16256189, 0.26305985, 0.33280683,\n",
       "        0.09227586, 0.124336  , 0.10667014, 0.17816925, 0.10858631]),\n",
       " 'score_time': array([0.00529027, 0.00230789, 0.0067451 , 0.00626421, 0.00278187,\n",
       "        0.00219011, 0.002738  , 0.00507784, 0.00373602, 0.003335  ]),\n",
       " 'test_score': array([0.94002586, 0.94794698, 0.94406725, 0.94148076, 0.94180407,\n",
       "        0.94358228, 0.94115745, 0.94228904, 0.94083414, 0.9442289 ]),\n",
       " 'train_score': array([0.9434519 , 0.94135004, 0.94232013, 0.94320938, 0.94288601,\n",
       "        0.94211803, 0.94316896, 0.94292643, 0.94292643, 0.94236055])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6532ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.17190792560577392\n",
      "Time for scoring classifier on the validation set: 0.004046630859375\n",
      "Accuracy of Train: 0.9426717865804365\n",
      "Accuracy of Validation: 0.9427416747494343\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cce8ce",
   "metadata": {},
   "source": [
    "### 1.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2f46aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 37.3 ms, total: 272 ms\n",
      "Wall time: 282 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gnb_clf_title = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results_title = cross_validate(gnb_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f75bb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0185039 , 0.01550007, 0.01448488, 0.01420498, 0.01976585,\n",
       "        0.01460099, 0.01365304, 0.01381922, 0.013942  , 0.0138061 ]),\n",
       " 'score_time': array([0.00384998, 0.00280905, 0.00282192, 0.00310493, 0.00515103,\n",
       "        0.00278401, 0.00283098, 0.00281978, 0.00280094, 0.00280285]),\n",
       " 'test_score': array([0.92935661, 0.93598448, 0.93404462, 0.92870999, 0.92709344,\n",
       "        0.93452958, 0.93178144, 0.93129648, 0.93388296, 0.93614614]),\n",
       " 'train_score': array([0.93298302, 0.93168957, 0.93136621, 0.9327405 , 0.92914309,\n",
       "        0.93168957, 0.93221504, 0.93367017, 0.93229588, 0.93080032])}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ebd2de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.01522810459136963\n",
      "Time for scoring classifier on the validation set: 0.0031775474548339845\n",
      "Accuracy of Train: 0.9318593371059013\n",
      "Accuracy of Validation: 0.9322825735531847\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525732da",
   "metadata": {},
   "source": [
    "### 1.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96f5753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 3.63 s, total: 2min 44s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svm_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results_title = cross_validate(svm_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3fbba556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.4379921 , 5.67425704, 5.26771498, 4.96598077, 5.93168688,\n",
       "        5.40598679, 4.94716382, 5.27366686, 6.62897682, 5.41495299]),\n",
       " 'score_time': array([2.8310039 , 2.37703395, 2.3134501 , 2.29794216, 2.37787485,\n",
       "        2.40980601, 2.25872207, 2.27631903, 2.43772912, 2.26801991]),\n",
       " 'test_score': array([0.94746201, 0.95457485, 0.95489816, 0.95376657, 0.95134174,\n",
       "        0.95279664, 0.9500485 , 0.95085677, 0.95279664, 0.9547365 ]),\n",
       " 'train_score': array([0.95533549, 0.95408246, 0.95347615, 0.95363783, 0.95468876,\n",
       "        0.95412288, 0.95464834, 0.95485044, 0.95444624, 0.95359741])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8341a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 5.494837903976441\n",
      "Time for scoring classifier on the validation set: 2.3847901105880736\n",
      "Accuracy of Train: 0.9542886014551334\n",
      "Accuracy of Validation: 0.9523278370514063\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6cbbe",
   "metadata": {},
   "source": [
    "### 1.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f4257ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 629 ms, total: 20.9 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results_title = cross_validate(rf_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3b265fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.86879277, 1.55097795, 1.70199513, 2.24268794, 1.8272028 ,\n",
       "        1.92721915, 1.861022  , 1.67886686, 1.77366495, 1.53000903]),\n",
       " 'score_time': array([0.09291911, 0.08585405, 0.08606267, 0.09484386, 0.12158513,\n",
       "        0.11577702, 0.08738303, 0.09752011, 0.08693719, 0.08548093]),\n",
       " 'test_score': array([0.94374394, 0.94827029, 0.94616877, 0.94697704, 0.9409958 ,\n",
       "        0.94746201, 0.94390559, 0.94390559, 0.94633042, 0.94616877]),\n",
       " 'train_score': array([0.99882781, 0.99890865, 0.99907033, 0.99882781, 0.99894907,\n",
       "        0.99890865, 0.99866613, 0.99894907, 0.99894907, 0.99882781])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "86279871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.7962438583374023\n",
      "Time for scoring classifier on the validation set: 0.09543631076812745\n",
      "Accuracy of Train: 0.9988884397736459\n",
      "Accuracy of Validation: 0.945392822502425\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548638cd",
   "metadata": {},
   "source": [
    "### 1.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10d01030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 219 ms, total: 11.2 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgboost_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results_title = cross_validate(xgboost_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "60dacf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.13135266, 1.09480977, 1.05672097, 1.00600076, 1.0791533 ,\n",
       "        1.10272479, 1.03688908, 1.01619005, 1.11051106, 1.00568104]),\n",
       " 'score_time': array([0.01792622, 0.01956701, 0.01663494, 0.01667833, 0.01923513,\n",
       "        0.01669621, 0.01694012, 0.01639891, 0.01827383, 0.01706004]),\n",
       " 'test_score': array([0.94519884, 0.95085677, 0.95118008, 0.94988684, 0.94600711,\n",
       "        0.95101843, 0.94843194, 0.94681539, 0.94827029, 0.95053346]),\n",
       " 'train_score': array([0.9525869 , 0.95133387, 0.95161681, 0.95226354, 0.95323363,\n",
       "        0.95153597, 0.95291027, 0.95181892, 0.95157639, 0.95185934])}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ebe5c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.064003348350525\n",
      "Time for scoring classifier on the validation set: 0.01754107475280762\n",
      "Accuracy of Train: 0.9520735650767987\n",
      "Accuracy of Validation: 0.9488199159392176\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3c2fe",
   "metadata": {},
   "source": [
    "## Storing Title Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "190dedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_title.loc['Logistic Regression', 'train_acc'] = lr_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'val_acc'] = lr_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'fit_time'] = lr_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Support Vector Machine', 'train_acc'] = svm_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'val_acc'] = svm_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'fit_time'] = svm_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Random Forest', 'train_acc'] = rf_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Random Forest', 'val_acc'] = rf_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Random Forest', 'fit_time'] = rf_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['XGBoost', 'train_acc'] = xgboost_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['XGBoost', 'val_acc'] = xgboost_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['XGBoost', 'fit_time'] = xgboost_cv_results_title[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dbb0b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.942672</td>\n",
       "      <td>0.942742</td>\n",
       "      <td>0.171908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.931859</td>\n",
       "      <td>0.932283</td>\n",
       "      <td>0.015228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.954289</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>5.494838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998888</td>\n",
       "      <td>0.945393</td>\n",
       "      <td>1.796244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.948820</td>\n",
       "      <td>1.064003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc   val_acc  fit_time\n",
       "Logistic Regression      0.942672  0.942742  0.171908\n",
       "Gaussian Naive Bayes     0.931859  0.932283  0.015228\n",
       "Support Vector Machine   0.954289  0.952328  5.494838\n",
       "Random Forest            0.998888  0.945393  1.796244\n",
       "XGBoost                  0.952074  0.948820  1.064003"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425a6cf",
   "metadata": {},
   "source": [
    "# 2. All Text - Metadata & Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4f2fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news.iloc[:,6:21]\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78aef219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2973</td>\n",
       "      <td>507</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>282</td>\n",
       "      <td>122</td>\n",
       "      <td>5.863905</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.556213</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>116</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1968</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>209</td>\n",
       "      <td>39</td>\n",
       "      <td>6.287540</td>\n",
       "      <td>28.454545</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>0.383387</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.7685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3688</td>\n",
       "      <td>595</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>344</td>\n",
       "      <td>148</td>\n",
       "      <td>6.198319</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>167</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2853</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>278</td>\n",
       "      <td>120</td>\n",
       "      <td>6.229258</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>0.606987</td>\n",
       "      <td>0.358079</td>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.9269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2417</td>\n",
       "      <td>431</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>244</td>\n",
       "      <td>40</td>\n",
       "      <td>5.607889</td>\n",
       "      <td>22.684211</td>\n",
       "      <td>0.566125</td>\n",
       "      <td>0.457077</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  sent_count  capital_word_count  quoted_word_count  \\\n",
       "0        2973         507          26                   5                  0   \n",
       "1        1968         313          11                   3                  0   \n",
       "2        3688         595          25                  42                  0   \n",
       "3        2853         458          15                   6                  0   \n",
       "4        2417         431          19                   0                  0   \n",
       "\n",
       "   stopword_count  unique_word_count  punct_count  avg_wordlength  \\\n",
       "0             195                282          122        5.863905   \n",
       "1             120                209           39        6.287540   \n",
       "2             220                344          148        6.198319   \n",
       "3             164                278          120        6.229258   \n",
       "4             197                244           40        5.607889   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  stopwords_vs_words  noun_count  \\\n",
       "0       19.500000         0.556213            0.384615         116   \n",
       "1       28.454545         0.667732            0.383387          94   \n",
       "2       23.800000         0.578151            0.369748         167   \n",
       "3       30.533333         0.606987            0.358079         143   \n",
       "4       22.684211         0.566125            0.457077          79   \n",
       "\n",
       "   adverb_count  sentiment_score  \n",
       "0            36          -0.9139  \n",
       "1            10          -0.7685  \n",
       "2            20          -0.9955  \n",
       "3            24          -0.9269  \n",
       "4            16           0.3134  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d461943",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7898d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83492ed",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a069523",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "55ec6cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiawei/opt/anaconda3/envs/BT4222/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.56 s, sys: 219 ms, total: 6.78 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "lr_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "lr_cv_results = cross_validate(lr_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "53a29ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.19882393, 0.1548872 , 0.22434378, 0.19513083, 0.187222  ,\n",
       "        0.26130104, 0.16943002, 0.16552305, 0.17698097, 0.17061496]),\n",
       " 'score_time': array([0.00555301, 0.00338888, 0.00374508, 0.00244403, 0.00262189,\n",
       "        0.00405407, 0.0030098 , 0.00254273, 0.00236011, 0.00219703]),\n",
       " 'test_score': array([0.86129971, 0.85693501, 0.8533786 , 0.86663434, 0.86420951,\n",
       "        0.8580666 , 0.85984481, 0.86744261, 0.85305529, 0.86372454]),\n",
       " 'train_score': array([0.86046888, 0.85877122, 0.86176233, 0.8589329 , 0.85856912,\n",
       "        0.86046888, 0.85957963, 0.85711399, 0.86228779, 0.85877122])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0d4df635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.19042577743530273\n",
      "Time for scoring classifier on the validation set: 0.0031916618347167967\n",
      "Accuracy of Train: 0.8596725949878741\n",
      "Accuracy of Validation: 0.8604591011962496\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427ec38",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f83d930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gnb_clf = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results = cross_validate(gnb_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c8284978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01579094, 0.01647902, 0.01483417, 0.01516294, 0.01523423,\n",
       "        0.01939082, 0.02032304, 0.02065516, 0.02066493, 0.02154994]),\n",
       " 'score_time': array([0.00309801, 0.00283813, 0.00304008, 0.00274181, 0.00557375,\n",
       "        0.00451994, 0.00408816, 0.00418901, 0.00599885, 0.00462389]),\n",
       " 'test_score': array([0.69915939, 0.70400905, 0.68913676, 0.68461041, 0.6933398 ,\n",
       "        0.68962173, 0.69689622, 0.6962496 , 0.6871969 , 0.69608794]),\n",
       " 'train_score': array([0.69122878, 0.70145513, 0.68823767, 0.68864188, 0.68569119,\n",
       "        0.69409863, 0.69090542, 0.69664511, 0.69353274, 0.68755053])}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ce65124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 0.01800851821899414\n",
      "Time for scoring classifier on the validation set: 0.004071164131164551\n",
      "Accuracy of Train: 0.6917987065481003\n",
      "Accuracy of Validation: 0.6936307791787908\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b747fee",
   "metadata": {},
   "source": [
    "### 2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de29b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 18s, sys: 5.4 s, total: 5min 23s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results = cross_validate(svm_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2a903354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([10.93141985, 11.12288809, 10.55821705, 10.92484903,  9.91726708,\n",
       "         9.72398472, 10.40651608,  9.47267985, 11.34606314,  9.85449076]),\n",
       " 'score_time': array([4.72791195, 4.61257195, 4.35795712, 5.11404991, 4.34168077,\n",
       "        4.59718513, 4.25743198, 4.2073741 , 4.33628392, 4.55799222]),\n",
       " 'test_score': array([0.90413838, 0.90171355, 0.90268348, 0.90656321, 0.90753314,\n",
       "        0.90462334, 0.90413838, 0.909473  , 0.89896541, 0.91189783]),\n",
       " 'train_score': array([0.90909458, 0.90901374, 0.90788197, 0.90743735, 0.90800323,\n",
       "        0.90763945, 0.90747777, 0.90739693, 0.90978173, 0.90541633])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eb264395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 10.425837564468384\n",
      "Time for scoring classifier on the validation set: 4.511043906211853\n",
      "Accuracy of Train: 0.907914308811641\n",
      "Accuracy of Validation: 0.9051729712253476\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e8230",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae6b0957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 s, sys: 1.04 s, total: 49.4 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results = cross_validate(rf_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "82c83298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.63230085, 4.35264325, 4.43624878, 5.25108194, 5.13699007,\n",
       "        4.96061206, 4.58648562, 4.197474  , 4.17424273, 4.39387488]),\n",
       " 'score_time': array([0.12995505, 0.10323787, 0.11905313, 0.14497495, 0.16381001,\n",
       "        0.14874196, 0.10498619, 0.09998298, 0.10900521, 0.09955287]),\n",
       " 'test_score': array([0.90139024, 0.90058196, 0.90203686, 0.90446169, 0.904785  ,\n",
       "        0.90397672, 0.90543162, 0.90575493, 0.89993534, 0.91319108]),\n",
       " 'train_score': array([1.        , 0.99995958, 0.99995958, 1.        , 0.99995958,\n",
       "        0.99995958, 1.        , 1.        , 1.        , 1.        ])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "96a08998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 4.612195420265198\n",
      "Time for scoring classifier on the validation set: 0.12233002185821533\n",
      "Accuracy of Train: 0.9999838318512531\n",
      "Accuracy of Validation: 0.9041545425153572\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc6710",
   "metadata": {},
   "source": [
    "### 2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e02db135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 287 ms, total: 15.5 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgboost_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results = cross_validate(xgboost_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "31d511e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.579983  , 1.50591302, 1.44315314, 1.435112  , 1.51270604,\n",
       "        1.47728205, 1.54843497, 1.49269199, 1.46346712, 1.47735286]),\n",
       " 'score_time': array([0.020926  , 0.01819706, 0.01838613, 0.0181911 , 0.01838422,\n",
       "        0.01802874, 0.01831388, 0.01866221, 0.01803184, 0.01886487]),\n",
       " 'test_score': array([0.89104429, 0.89185257, 0.89395409, 0.89945037, 0.8942774 ,\n",
       "        0.89460071, 0.89476237, 0.90074361, 0.89314581, 0.90607824]),\n",
       " 'train_score': array([0.90626516, 0.90505255, 0.90412288, 0.90307195, 0.90493129,\n",
       "        0.90323363, 0.90388036, 0.90254648, 0.9041633 , 0.90194018])}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f134aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for fitting classifier on the train set: 1.493609619140625\n",
      "Time for scoring classifier on the validation set: 0.018598604202270507\n",
      "Accuracy of Train: 0.9039207760711401\n",
      "Accuracy of Validation: 0.8959909473003556\n"
     ]
    }
   ],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ad9ce",
   "metadata": {},
   "source": [
    "## Storing All Text Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "15ec0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_text = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_all_text.loc['Logistic Regression', 'train_acc'] = lr_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'val_acc'] = lr_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'fit_time'] = lr_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Support Vector Machine', 'train_acc'] = svm_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'val_acc'] = svm_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'fit_time'] = svm_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Random Forest', 'train_acc'] = rf_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'val_acc'] = rf_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'fit_time'] = rf_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['XGBoost', 'train_acc'] = xgboost_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'val_acc'] = xgboost_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'fit_time'] = xgboost_cv_results[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d27ce64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.859673</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.190426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.691799</td>\n",
       "      <td>0.693631</td>\n",
       "      <td>0.018009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.907914</td>\n",
       "      <td>0.905173</td>\n",
       "      <td>10.425838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.904155</td>\n",
       "      <td>4.612195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.903921</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>1.493610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc   val_acc   fit_time\n",
       "Logistic Regression      0.859673  0.860459   0.190426\n",
       "Gaussian Naive Bayes     0.691799  0.693631   0.018009\n",
       "Support Vector Machine   0.907914  0.905173  10.425838\n",
       "Random Forest            0.999984  0.904155   4.612195\n",
       "XGBoost                  0.903921  0.895991   1.493610"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423eaeb",
   "metadata": {},
   "source": [
    "# 3. Comparing Validation Accuracy and Fit Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4c1614b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_07cdf\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Title Only</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_07cdf_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_07cdf_level0_col1\" class=\"col_heading level0 col1\" >val_acc</th>\n",
       "      <th id=\"T_07cdf_level0_col2\" class=\"col_heading level0 col2\" >fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_07cdf_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_07cdf_row0_col0\" class=\"data row0 col0\" >0.942672</td>\n",
       "      <td id=\"T_07cdf_row0_col1\" class=\"data row0 col1\" >0.942742</td>\n",
       "      <td id=\"T_07cdf_row0_col2\" class=\"data row0 col2\" >0.171908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07cdf_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_07cdf_row1_col0\" class=\"data row1 col0\" >0.931859</td>\n",
       "      <td id=\"T_07cdf_row1_col1\" class=\"data row1 col1\" >0.932283</td>\n",
       "      <td id=\"T_07cdf_row1_col2\" class=\"data row1 col2\" >0.015228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07cdf_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_07cdf_row2_col0\" class=\"data row2 col0\" >0.954289</td>\n",
       "      <td id=\"T_07cdf_row2_col1\" class=\"data row2 col1\" >0.952328</td>\n",
       "      <td id=\"T_07cdf_row2_col2\" class=\"data row2 col2\" >5.494838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07cdf_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_07cdf_row3_col0\" class=\"data row3 col0\" >0.998888</td>\n",
       "      <td id=\"T_07cdf_row3_col1\" class=\"data row3 col1\" >0.945393</td>\n",
       "      <td id=\"T_07cdf_row3_col2\" class=\"data row3 col2\" >1.796244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07cdf_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_07cdf_row4_col0\" class=\"data row4 col0\" >0.952074</td>\n",
       "      <td id=\"T_07cdf_row4_col1\" class=\"data row4 col1\" >0.948820</td>\n",
       "      <td id=\"T_07cdf_row4_col2\" class=\"data row4 col2\" >1.064003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3cf2a\" style='display:inline'>\n",
       "  <caption>Title & Text</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3cf2a_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_3cf2a_level0_col1\" class=\"col_heading level0 col1\" >val_acc</th>\n",
       "      <th id=\"T_3cf2a_level0_col2\" class=\"col_heading level0 col2\" >fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3cf2a_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_3cf2a_row0_col0\" class=\"data row0 col0\" >0.859673</td>\n",
       "      <td id=\"T_3cf2a_row0_col1\" class=\"data row0 col1\" >0.860459</td>\n",
       "      <td id=\"T_3cf2a_row0_col2\" class=\"data row0 col2\" >0.190426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3cf2a_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_3cf2a_row1_col0\" class=\"data row1 col0\" >0.691799</td>\n",
       "      <td id=\"T_3cf2a_row1_col1\" class=\"data row1 col1\" >0.693631</td>\n",
       "      <td id=\"T_3cf2a_row1_col2\" class=\"data row1 col2\" >0.018009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3cf2a_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_3cf2a_row2_col0\" class=\"data row2 col0\" >0.907914</td>\n",
       "      <td id=\"T_3cf2a_row2_col1\" class=\"data row2 col1\" >0.905173</td>\n",
       "      <td id=\"T_3cf2a_row2_col2\" class=\"data row2 col2\" >10.425838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3cf2a_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_3cf2a_row3_col0\" class=\"data row3 col0\" >0.999984</td>\n",
       "      <td id=\"T_3cf2a_row3_col1\" class=\"data row3 col1\" >0.904155</td>\n",
       "      <td id=\"T_3cf2a_row3_col2\" class=\"data row3 col2\" >4.612195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3cf2a_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_3cf2a_row4_col0\" class=\"data row4 col0\" >0.903921</td>\n",
       "      <td id=\"T_3cf2a_row4_col1\" class=\"data row4 col1\" >0.895991</td>\n",
       "      <td id=\"T_3cf2a_row4_col2\" class=\"data row4 col2\" >1.493610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html \n",
    "\n",
    "results_title_style = results_title.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_text.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fc7b0",
   "metadata": {},
   "source": [
    "1. SVM takes the longest to fit across both experiments\n",
    "2. For title only, although SVM performed the best, XGBoost wasn't far off in terms of validation accuracy and took 6.5 times less to fit\n",
    "3. For all text, although SVM performed the best, the long fitting time dissauades us from using it, instead XGBoost or even Random Forest would be a better choice\n",
    "4. On average, validation accuracy for title is higher than that of all text, hence we could say that we are able to predict if an article is real based on the title alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6843c4",
   "metadata": {},
   "source": [
    "# 4. Title - Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9181b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b9b431bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.942896</td>\n",
       "      <td>0.945292</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>0.945144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.931773</td>\n",
       "      <td>0.930031</td>\n",
       "      <td>0.929666</td>\n",
       "      <td>0.929516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.954116</td>\n",
       "      <td>0.953440</td>\n",
       "      <td>0.953305</td>\n",
       "      <td>0.953235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998739</td>\n",
       "      <td>0.945163</td>\n",
       "      <td>0.945058</td>\n",
       "      <td>0.945046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.951303</td>\n",
       "      <td>0.949302</td>\n",
       "      <td>0.949171</td>\n",
       "      <td>0.949125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc  test_acc  F1-Weighted  F2-Weighted\n",
       "Logistic Regression      0.942896  0.945292     0.945169     0.945144\n",
       "Gaussian Naive Bayes     0.931773  0.930031     0.929666     0.929516\n",
       "Support Vector Machine   0.954116  0.953440     0.953305     0.953235\n",
       "Random Forest            0.998739  0.945163     0.945058     0.945046\n",
       "XGBoost                  0.951303  0.949302     0.949171     0.949125"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr_clf_title = sklearn.base.clone(lr_clf_title)\n",
    "lr_clf_title.fit(X_train_title, y_train_title)\n",
    "lr_clf_title_train_acc = lr_clf_title.score(X_train_title, y_train_title)\n",
    "lr_clf_title_test_acc = lr_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Logistic Regression', 'train_acc'] = lr_clf_title_train_acc\n",
    "results_title_final.loc['Logistic Regression', 'test_acc'] = lr_clf_title_test_acc\n",
    "lr_y_pred_title = lr_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Logistic Regression', 'F1-Weighted'] = fbeta_score(y_test_title, lr_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Logistic Regression', 'F2-Weighted'] = fbeta_score(y_test_title, lr_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "gnb_clf_title = sklearn.base.clone(gnb_clf_title)\n",
    "gnb_clf_title.fit(X_train_title, y_train_title)\n",
    "gnb_clf_title_train_acc = gnb_clf_title.score(X_train_title, y_train_title)\n",
    "gnb_clf_title_test_acc = gnb_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_clf_title_train_acc\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_clf_title_test_acc\n",
    "gnb_y_pred_title = gnb_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'F1-Weighted'] = fbeta_score(y_test_title, gnb_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'F2-Weighted'] = fbeta_score(y_test_title, gnb_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# SVM\n",
    "svm_clf_title = sklearn.base.clone(svm_clf_title)\n",
    "svm_clf_title.fit(X_train_title, y_train_title)\n",
    "svm_clf_title_train_acc = svm_clf_title.score(X_train_title, y_train_title)\n",
    "svm_clf_title_test_acc = svm_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Support Vector Machine', 'train_acc'] = svm_clf_title_train_acc\n",
    "results_title_final.loc['Support Vector Machine', 'test_acc'] = svm_clf_title_test_acc\n",
    "svm_y_pred_title = svm_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Support Vector Machine', 'F1-Weighted'] = fbeta_score(y_test_title, svm_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Support Vector Machine', 'F2-Weighted'] = fbeta_score(y_test_title, svm_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# Random Forest\n",
    "rf_clf_title = sklearn.base.clone(rf_clf_title)\n",
    "rf_clf_title.fit(X_train_title, y_train_title)\n",
    "rf_clf_title_train_acc = rf_clf_title.score(X_train_title, y_train_title)\n",
    "rf_clf_title_test_acc = rf_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Random Forest', 'train_acc'] = rf_clf_title_train_acc\n",
    "results_title_final.loc['Random Forest', 'test_acc'] = rf_clf_title_test_acc\n",
    "rf_y_pred_title = rf_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Random Forest', 'F1-Weighted'] = fbeta_score(y_test_title, rf_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Random Forest', 'F2-Weighted'] = fbeta_score(y_test_title, rf_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# XGBoost\n",
    "xgboost_clf_title = sklearn.base.clone(xgboost_clf_title)\n",
    "xgboost_clf_title.fit(X_train_title, y_train_title)\n",
    "xgboost_clf_title_train_acc = xgboost_clf_title.score(X_train_title, y_train_title)\n",
    "xgboost_clf_title_test_acc = xgboost_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['XGBoost', 'train_acc'] = xgboost_clf_title_train_acc\n",
    "results_title_final.loc['XGBoost', 'test_acc'] = xgboost_clf_title_test_acc\n",
    "xgboost_y_pred_title = xgboost_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['XGBoost', 'F1-Weighted'] = fbeta_score(y_test_title, xgboost_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['XGBoost', 'F2-Weighted'] = fbeta_score(y_test_title, xgboost_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "results_title_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65187ce9",
   "metadata": {},
   "source": [
    "# 5. All Text - Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0d2c4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5852caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.859891</td>\n",
       "      <td>0.850362</td>\n",
       "      <td>0.849962</td>\n",
       "      <td>0.850085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.689614</td>\n",
       "      <td>0.696198</td>\n",
       "      <td>0.672898</td>\n",
       "      <td>0.678883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.908491</td>\n",
       "      <td>0.896793</td>\n",
       "      <td>0.896624</td>\n",
       "      <td>0.896671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900802</td>\n",
       "      <td>0.900746</td>\n",
       "      <td>0.900771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.903673</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.886607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_acc  test_acc  F1-Weighted  F2-Weighted\n",
       "Logistic Regression      0.859891  0.850362     0.849962     0.850085\n",
       "Gaussian Naive Bayes     0.689614  0.696198     0.672898     0.678883\n",
       "Support Vector Machine   0.908491  0.896793     0.896624     0.896671\n",
       "Random Forest            1.000000  0.900802     0.900746     0.900771\n",
       "XGBoost                  0.903673  0.886834     0.886547     0.886607"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr_clf = sklearn.base.clone(lr_clf)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_all_train_acc = lr_clf.score(X_train, y_train)\n",
    "lr_all_test_acc = lr_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Logistic Regression', 'train_acc'] = lr_all_train_acc\n",
    "results_all_final.loc['Logistic Regression', 'test_acc'] = lr_all_test_acc\n",
    "lr_y_pred = lr_clf.predict(X_test)\n",
    "results_all_final.loc['Logistic Regression', 'F1-Weighted'] = fbeta_score(y_test, lr_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Logistic Regression', 'F2-Weighted'] = fbeta_score(y_test, lr_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# Naive Bayes\n",
    "gnb_clf = sklearn.base.clone(gnb_clf)\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_all_train_acc = gnb_clf.score(X_train, y_train)\n",
    "gnb_all_test_acc = gnb_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_all_train_acc\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_all_test_acc\n",
    "gnb_y_pred = gnb_clf.predict(X_test)\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'F1-Weighted'] = fbeta_score(y_test, gnb_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'F2-Weighted'] = fbeta_score(y_test, gnb_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# SVM\n",
    "svm_clf = sklearn.base.clone(svm_clf)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_all_train_acc = svm_clf.score(X_train, y_train)\n",
    "svm_all_test_acc = svm_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Support Vector Machine', 'train_acc'] = svm_all_train_acc\n",
    "results_all_final.loc['Support Vector Machine', 'test_acc'] = svm_all_test_acc\n",
    "svm_y_pred = svm_clf.predict(X_test)\n",
    "results_all_final.loc['Support Vector Machine', 'F1-Weighted'] = fbeta_score(y_test, svm_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Support Vector Machine', 'F2-Weighted'] = fbeta_score(y_test, svm_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = sklearn.base.clone(rf_clf)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_all_train_acc = rf_clf.score(X_train, y_train)\n",
    "rf_all_test_acc = rf_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Random Forest', 'train_acc'] = rf_all_train_acc\n",
    "results_all_final.loc['Random Forest', 'test_acc'] = rf_all_test_acc\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "results_all_final.loc['Random Forest', 'F1-Weighted'] = fbeta_score(y_test, rf_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Random Forest', 'F2-Weighted'] = fbeta_score(y_test, rf_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# XGBoost\n",
    "xgboost_clf = sklearn.base.clone(xgboost_clf)\n",
    "xgboost_clf.fit(X_train, y_train)\n",
    "xgboost_all_train_acc = xgboost_clf.score(X_train, y_train)\n",
    "xgboost_all_test_acc = xgboost_clf.score(X_test, y_test)\n",
    "results_all_final.loc['XGBoost', 'train_acc'] = xgboost_all_train_acc\n",
    "results_all_final.loc['XGBoost', 'test_acc'] = xgboost_all_test_acc\n",
    "xgboost_y_pred = xgboost_clf.predict(X_test)\n",
    "results_all_final.loc['XGBoost', 'F1-Weighted'] = fbeta_score(y_test, xgboost_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['XGBoost', 'F2-Weighted'] = fbeta_score(y_test, xgboost_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "results_all_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eabab621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fd092\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Title Only</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd092_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_fd092_level0_col1\" class=\"col_heading level0 col1\" >test_acc</th>\n",
       "      <th id=\"T_fd092_level0_col2\" class=\"col_heading level0 col2\" >F1-Weighted</th>\n",
       "      <th id=\"T_fd092_level0_col3\" class=\"col_heading level0 col3\" >F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd092_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_fd092_row0_col0\" class=\"data row0 col0\" >0.942896</td>\n",
       "      <td id=\"T_fd092_row0_col1\" class=\"data row0 col1\" >0.945292</td>\n",
       "      <td id=\"T_fd092_row0_col2\" class=\"data row0 col2\" >0.945169</td>\n",
       "      <td id=\"T_fd092_row0_col3\" class=\"data row0 col3\" >0.945144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd092_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_fd092_row1_col0\" class=\"data row1 col0\" >0.931773</td>\n",
       "      <td id=\"T_fd092_row1_col1\" class=\"data row1 col1\" >0.930031</td>\n",
       "      <td id=\"T_fd092_row1_col2\" class=\"data row1 col2\" >0.929666</td>\n",
       "      <td id=\"T_fd092_row1_col3\" class=\"data row1 col3\" >0.929516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd092_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_fd092_row2_col0\" class=\"data row2 col0\" >0.954116</td>\n",
       "      <td id=\"T_fd092_row2_col1\" class=\"data row2 col1\" >0.953440</td>\n",
       "      <td id=\"T_fd092_row2_col2\" class=\"data row2 col2\" >0.953305</td>\n",
       "      <td id=\"T_fd092_row2_col3\" class=\"data row2 col3\" >0.953235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd092_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_fd092_row3_col0\" class=\"data row3 col0\" >0.998739</td>\n",
       "      <td id=\"T_fd092_row3_col1\" class=\"data row3 col1\" >0.945163</td>\n",
       "      <td id=\"T_fd092_row3_col2\" class=\"data row3 col2\" >0.945058</td>\n",
       "      <td id=\"T_fd092_row3_col3\" class=\"data row3 col3\" >0.945046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd092_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_fd092_row4_col0\" class=\"data row4 col0\" >0.951303</td>\n",
       "      <td id=\"T_fd092_row4_col1\" class=\"data row4 col1\" >0.949302</td>\n",
       "      <td id=\"T_fd092_row4_col2\" class=\"data row4 col2\" >0.949171</td>\n",
       "      <td id=\"T_fd092_row4_col3\" class=\"data row4 col3\" >0.949125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bcb77\" style='display:inline'>\n",
       "  <caption>Title & Text</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bcb77_level0_col0\" class=\"col_heading level0 col0\" >train_acc</th>\n",
       "      <th id=\"T_bcb77_level0_col1\" class=\"col_heading level0 col1\" >test_acc</th>\n",
       "      <th id=\"T_bcb77_level0_col2\" class=\"col_heading level0 col2\" >F1-Weighted</th>\n",
       "      <th id=\"T_bcb77_level0_col3\" class=\"col_heading level0 col3\" >F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bcb77_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_bcb77_row0_col0\" class=\"data row0 col0\" >0.859891</td>\n",
       "      <td id=\"T_bcb77_row0_col1\" class=\"data row0 col1\" >0.850362</td>\n",
       "      <td id=\"T_bcb77_row0_col2\" class=\"data row0 col2\" >0.849962</td>\n",
       "      <td id=\"T_bcb77_row0_col3\" class=\"data row0 col3\" >0.850085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcb77_level0_row1\" class=\"row_heading level0 row1\" >Gaussian Naive Bayes</th>\n",
       "      <td id=\"T_bcb77_row1_col0\" class=\"data row1 col0\" >0.689614</td>\n",
       "      <td id=\"T_bcb77_row1_col1\" class=\"data row1 col1\" >0.696198</td>\n",
       "      <td id=\"T_bcb77_row1_col2\" class=\"data row1 col2\" >0.672898</td>\n",
       "      <td id=\"T_bcb77_row1_col3\" class=\"data row1 col3\" >0.678883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcb77_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
       "      <td id=\"T_bcb77_row2_col0\" class=\"data row2 col0\" >0.908491</td>\n",
       "      <td id=\"T_bcb77_row2_col1\" class=\"data row2 col1\" >0.896793</td>\n",
       "      <td id=\"T_bcb77_row2_col2\" class=\"data row2 col2\" >0.896624</td>\n",
       "      <td id=\"T_bcb77_row2_col3\" class=\"data row2 col3\" >0.896671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcb77_level0_row3\" class=\"row_heading level0 row3\" >Random Forest</th>\n",
       "      <td id=\"T_bcb77_row3_col0\" class=\"data row3 col0\" >1.000000</td>\n",
       "      <td id=\"T_bcb77_row3_col1\" class=\"data row3 col1\" >0.900802</td>\n",
       "      <td id=\"T_bcb77_row3_col2\" class=\"data row3 col2\" >0.900746</td>\n",
       "      <td id=\"T_bcb77_row3_col3\" class=\"data row3 col3\" >0.900771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcb77_level0_row4\" class=\"row_heading level0 row4\" >XGBoost</th>\n",
       "      <td id=\"T_bcb77_row4_col0\" class=\"data row4 col0\" >0.903673</td>\n",
       "      <td id=\"T_bcb77_row4_col1\" class=\"data row4 col1\" >0.886834</td>\n",
       "      <td id=\"T_bcb77_row4_col2\" class=\"data row4 col2\" >0.886547</td>\n",
       "      <td id=\"T_bcb77_row4_col3\" class=\"data row4 col3\" >0.886607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_title_style = results_title_final.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_final.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efa73a",
   "metadata": {},
   "source": [
    "# 6. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac95266",
   "metadata": {},
   "source": [
    "## 6.1 All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5ac1991",
   "metadata": {
    "id": "ca6bdbc9"
   },
   "outputs": [],
   "source": [
    "X = news['all_text']\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22c173d9",
   "metadata": {
    "id": "5df3c627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: all_text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a774c7",
   "metadata": {},
   "source": [
    "### 6.1.1 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d200fa7",
   "metadata": {
    "id": "67a86a1e"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8af0c",
   "metadata": {},
   "source": [
    "### 6.1.2 Transforming All Text to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "970d278e",
   "metadata": {
    "id": "DKLXJF36ixTI"
   },
   "outputs": [],
   "source": [
    "vectorization = TfidfVectorizer()\n",
    "X_train_vec = vectorization.fit_transform(X_train)\n",
    "X_test_vec = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b884a7b",
   "metadata": {},
   "source": [
    "### 6.1.3 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c76f268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc26b4",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "110e0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_vec, y_train)\n",
    "nlp_results['LR'] = [LR.score(X_train_vec, y_train), LR.score(X_test_vec, y_test)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76cbd1",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8107204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB().fit(X_train_vec, y_train)\n",
    "nlp_results['NB']= [NB.score(X_train_vec, y_train), NB.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2cab1",
   "metadata": {},
   "source": [
    "#### 6.1.3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "830ef8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM.fit(X_train_vec, y_train)\n",
    "nlp_results['SVM']= [SVM.score(X_train_vec, y_train), SVM.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed00b9d",
   "metadata": {},
   "source": [
    "#### 6.1.3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96cba833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9884563150746944, 0.9811174340403518], 'NB': [0.9457737825777662, 0.9372736678737713], 'SVM': [0.99899760719136, 0.987325400931195], 'RFC': [1.0, 0.9714174857734093]}\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=1)\n",
    "RFC.fit(X_train_vec, y_train)\n",
    "\n",
    "nlp_results['RFC']= [RFC.score(X_train_vec, y_train), RFC.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d311af",
   "metadata": {},
   "source": [
    "#### 6.1.3.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47324f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(random_state=1)\n",
    "XGB.fit(X_train_vec, y_train)\n",
    "nlp_results['XGB'] = [XGB.score(X_train_vec, y_train), XGB.score(X_test_vec, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bfcd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RFC': [1.0, 0.9714174857734093], 'XGB': [1.0, 0.987842731505432], 'LR': [0.9884563150746944, 0.9811174340403518], 'NB': [0.9457737825777662, 0.9372736678737713], 'SVM': [0.99899760719136, 0.987325400931195]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa00d6",
   "metadata": {},
   "source": [
    "### 6.1.4 Storing All Test TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cd9bdc",
   "metadata": {
    "id": "c8833b85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.981117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.945774</td>\n",
       "      <td>0.937274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.987325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc\n",
       "Logistic Regression       0.988456  0.981117\n",
       "Multinomial Naive Bayes   0.945774  0.937274\n",
       "Support Vector Machine    0.998998  0.987325\n",
       "Random Forest             1.000000  0.971417\n",
       "XGBoost                   1.000000  0.987843"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_results_all_text = pd.DataFrame()\n",
    "\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'train_acc'] = nlp_results['LR'][0]\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'test_acc'] = nlp_results['LR'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results['NB'][0]\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results['NB'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'train_acc'] = nlp_results['SVM'][0]\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'test_acc'] = nlp_results['SVM'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['Random Forest', 'train_acc'] = nlp_results['RFC'][0]\n",
    "tfidf_results_all_text.loc['Random Forest', 'test_acc'] = nlp_results['RFC'][1]\n",
    "\n",
    "tfidf_results_all_text.loc['XGBoost', 'train_acc'] = nlp_results['XGB'][0]\n",
    "tfidf_results_all_text.loc['XGBoost', 'test_acc'] = nlp_results['XGB'][1]\n",
    "tfidf_results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40ce20",
   "metadata": {
    "id": "c4ed466d"
   },
   "source": [
    "## 6.2 Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a671788",
   "metadata": {
    "id": "c291759a"
   },
   "outputs": [],
   "source": [
    "X2 = news['title']\n",
    "y2 = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f3bc99e",
   "metadata": {
    "id": "c7d9e9e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922f25f",
   "metadata": {},
   "source": [
    "### 6.2.1 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd76162f",
   "metadata": {
    "id": "cefe6309"
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1e865",
   "metadata": {},
   "source": [
    "### 6.2.2 Transforming Title to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61db8252",
   "metadata": {
    "id": "Z2WUUtNmjd3w"
   },
   "outputs": [],
   "source": [
    "# Converting text to vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorization2 = TfidfVectorizer()\n",
    "X_train_vec2 = vectorization2.fit_transform(X_train2)\n",
    "X_test_vec2 = vectorization2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077fc53",
   "metadata": {},
   "source": [
    "### 6.2.3 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78dccdfc",
   "metadata": {
    "id": "2gUk5E5yhKxc"
   },
   "outputs": [],
   "source": [
    "nlp_results_title = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a6a17",
   "metadata": {},
   "source": [
    "#### 6.2.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "165011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = LogisticRegression()\n",
    "LR2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['LR'] = [LR2.score(X_train_vec2, y_train2), LR2.score(X_test_vec2, y_test2)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf862d3",
   "metadata": {},
   "source": [
    "#### 6.2.3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB2 = MultinomialNB().fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['NB']= [NB2.score(X_train_vec2, y_train2), NB2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a16702",
   "metadata": {},
   "source": [
    "#### 6.2.3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f27826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM2 = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['SVM']= [SVM2.score(X_train_vec2, y_train2), SVM2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c23bc",
   "metadata": {},
   "source": [
    "#### 6.2.3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1546a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC2 = RandomForestClassifier(random_state=1)\n",
    "RFC2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['RFC']= [RFC2.score(X_train_vec2, y_train2), RFC2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8ccbb",
   "metadata": {},
   "source": [
    "#### 6.2.3.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40cbf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2 = XGBClassifier(random_state=1)\n",
    "XGB2.fit(X_train_vec2, y_train2)\n",
    "nlp_results_title['XGB'] = [XGB2.score(X_train_vec2, y_train2), XGB2.score(X_test_vec2, y_test2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8feef003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9650779279570588, 0.9443869632695292], 'NB': [0.957964172540904, 0.9408949818934299], 'RFC': [1.0, 0.9425763062596999], 'XGB': [0.9545366358403932, 0.9335230212105535], 'SVM': [0.9959904287654401, 0.9511122607346094]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1102476",
   "metadata": {},
   "source": [
    "### 6.2.4 Storing Title TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0960c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.965078</td>\n",
       "      <td>0.944387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.940895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.951112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.954537</td>\n",
       "      <td>0.933523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc\n",
       "Logistic Regression       0.965078  0.944387\n",
       "Multinomial Naive Bayes   0.957964  0.940895\n",
       "Support Vector Machine    0.995990  0.951112\n",
       "Random Forest             1.000000  0.942576\n",
       "XGBoost                   0.954537  0.933523"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_results_title = pd.DataFrame()\n",
    "\n",
    "tfidf_results_title.loc['Logistic Regression', 'train_acc'] = nlp_results_title['LR'][0]\n",
    "tfidf_results_title.loc['Logistic Regression', 'test_acc'] = nlp_results_title['LR'][1]\n",
    "\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results_title['NB'][0]\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results_title['NB'][1]\n",
    "\n",
    "tfidf_results_title.loc['Support Vector Machine', 'train_acc'] = nlp_results_title['SVM'][0]\n",
    "tfidf_results_title.loc['Support Vector Machine', 'test_acc'] = nlp_results_title['SVM'][1]\n",
    "\n",
    "tfidf_results_title.loc['Random Forest', 'train_acc'] = nlp_results_title['RFC'][0]\n",
    "tfidf_results_title.loc['Random Forest', 'test_acc'] = nlp_results_title['RFC'][1]\n",
    "\n",
    "tfidf_results_title.loc['XGBoost', 'train_acc'] = nlp_results_title['XGB'][0]\n",
    "tfidf_results_title.loc['XGBoost', 'test_acc'] = nlp_results_title['XGB'][1]\n",
    "tfidf_results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbed3e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bbe61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987033547209766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7999999999999999,\n",
       " 'max_depth': 15,\n",
       " 'learning_rate': 0.3,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'colsample_bylevel': 0.7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {'max_depth': [3, 6, 10, 15],\n",
    "      'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "      'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "      }\n",
    "search = RandomizedSearchCV(estimator=XGB,\n",
    "                         param_distributions=params,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=2, random_state=1)\n",
    "search.fit(X_train_vec, y_train)\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a206ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9879720641489912\n"
     ]
    }
   ],
   "source": [
    "XGB_tuned = XGBClassifier(**search.best_params_, random_state=1)\n",
    "XGB_tuned.fit(X_train_vec, y_train)\n",
    "nlp_results['XGB Tuned'] = [XGB_tuned.score(X_train_vec, y_train), XGB_tuned.score(X_test_vec, y_test)]\n",
    "print(\"Training Accuracy:\", nlp_results['XGB Tuned'][0])\n",
    "print(\"Testing Accuracy:\", nlp_results['XGB Tuned'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dff928",
   "metadata": {},
   "source": [
    "Accuracy went up by a marginal 0.02% after tuning hyperparameters. Hence, hyperparameter tuning may not be worth the efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7dac4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB ROC_AUC: 0.999339845224613\n",
      "XGB Tuned ROC_AUC: 0.9992480316022218\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = XGB.predict_proba(X_test_vec)[:,1]\n",
    "y_pred_prob2 = XGB_tuned.predict_proba(X_test_vec)[:,1]\n",
    "print('XGB ROC_AUC:', metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "print('XGB Tuned ROC_AUC:', metrics.roc_auc_score(y_test, y_pred_prob2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a6d3a1c9702cbdea61a84eb923333e247e4db67d8a1f6fe21a7310eabf978f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
