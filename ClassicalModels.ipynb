{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c06bffc",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fcb45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import sklearn\n",
    "\n",
    "# Model Building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d03981",
   "metadata": {},
   "source": [
    "# 1. Title - Metadata & Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0928793",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"news_final.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = news.iloc[:,22:]\n",
    "y_title = news['fake']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628e9f7",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(X_title, y_title, test_size=0.2, shuffle=True, random_state=1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bb181",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159de4b",
   "metadata": {},
   "source": [
    "### 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029972ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_clf_title = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "lr_cv_results_title = cross_validate(lr_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e37ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cce8ce",
   "metadata": {},
   "source": [
    "### 1.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gnb_clf_title = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results_title = cross_validate(gnb_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525732da",
   "metadata": {},
   "source": [
    "### 1.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svm_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results_title = cross_validate(svm_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbba556",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6cbbe",
   "metadata": {},
   "source": [
    "### 1.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4257ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results_title = cross_validate(rf_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b265fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86279871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548638cd",
   "metadata": {},
   "source": [
    "### 1.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d01030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgboost_clf_title = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results_title = cross_validate(xgboost_clf_title, X_train_title, y_train_title, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dacf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_cv_results_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results_title[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results_title[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results_title[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results_title[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3c2fe",
   "metadata": {},
   "source": [
    "## Storing Title Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190dedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_title.loc['Logistic Regression', 'train_acc'] = lr_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'val_acc'] = lr_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Logistic Regression', 'fit_time'] = lr_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Support Vector Machine', 'train_acc'] = svm_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'val_acc'] = svm_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Support Vector Machine', 'fit_time'] = svm_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['Random Forest', 'train_acc'] = rf_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['Random Forest', 'val_acc'] = rf_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['Random Forest', 'fit_time'] = rf_cv_results_title[\"fit_time\"].mean()\n",
    "\n",
    "results_title.loc['XGBoost', 'train_acc'] = xgboost_cv_results_title[\"train_score\"].mean()\n",
    "results_title.loc['XGBoost', 'val_acc'] = xgboost_cv_results_title[\"test_score\"].mean()\n",
    "results_title.loc['XGBoost', 'fit_time'] = xgboost_cv_results_title[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425a6cf",
   "metadata": {},
   "source": [
    "# 2. All Text - Metadata & Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news.iloc[:,6:21]\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aef219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d461943",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83492ed",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a069523",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "lr_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=1))\n",
    "])\n",
    "\n",
    "lr_cv_results = cross_validate(lr_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a29ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4df635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {lr_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {lr_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {lr_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {lr_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427ec38",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gnb_clf = Pipeline([\n",
    "    ('scale', Normalizer()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_cv_results = cross_validate(gnb_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8284978",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce65124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {gnb_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {gnb_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {gnb_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {gnb_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b747fee",
   "metadata": {},
   "source": [
    "### 2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_cv_results = cross_validate(svm_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a903354",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb264395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {svm_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {svm_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {svm_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {svm_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e8230",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "rf_cv_results = cross_validate(rf_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c83298",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a08998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {rf_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {rf_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {rf_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {rf_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc6710",
   "metadata": {},
   "source": [
    "### 2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02db135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgboost_clf = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', XGBClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "xgboost_cv_results = cross_validate(xgboost_clf, X_train, y_train, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d511e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time for fitting classifier on the train set: {xgboost_cv_results[\"fit_time\"].mean()}')\n",
    "print(f'Time for scoring classifier on the validation set: {xgboost_cv_results[\"score_time\"].mean()}')\n",
    "print(f'Accuracy of Train: {xgboost_cv_results[\"train_score\"].mean()}')\n",
    "print(f'Accuracy of Validation: {xgboost_cv_results[\"test_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ad9ce",
   "metadata": {},
   "source": [
    "## Storing All Text Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_text = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])\n",
    "\n",
    "results_all_text.loc['Logistic Regression', 'train_acc'] = lr_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'val_acc'] = lr_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Logistic Regression', 'fit_time'] = lr_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'val_acc'] = gnb_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Gaussian Naive Bayes', 'fit_time'] = gnb_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Support Vector Machine', 'train_acc'] = svm_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'val_acc'] = svm_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Support Vector Machine', 'fit_time'] = svm_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['Random Forest', 'train_acc'] = rf_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'val_acc'] = rf_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['Random Forest', 'fit_time'] = rf_cv_results[\"fit_time\"].mean()\n",
    "\n",
    "results_all_text.loc['XGBoost', 'train_acc'] = xgboost_cv_results[\"train_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'val_acc'] = xgboost_cv_results[\"test_score\"].mean()\n",
    "results_all_text.loc['XGBoost', 'fit_time'] = xgboost_cv_results[\"fit_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ce64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423eaeb",
   "metadata": {},
   "source": [
    "# 3. Comparing Validation Accuracy and Fit Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1614b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html \n",
    "\n",
    "results_title_style = results_title.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_text.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fc7b0",
   "metadata": {},
   "source": [
    "1. SVM takes the longest to fit across both experiments\n",
    "2. For title only, although SVM performed the best, XGBoost wasn't far off in terms of validation accuracy and took 6.5 times less to fit\n",
    "3. For all text, although SVM performed the best, the long fitting time dissauades us from using it, instead XGBoost or even Random Forest would be a better choice\n",
    "4. On average, validation accuracy for title is higher than that of all text, hence we could say that we are able to predict if an article is real based on the title alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6843c4",
   "metadata": {},
   "source": [
    "# 4. Title - Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b431bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_clf_title = sklearn.base.clone(lr_clf_title)\n",
    "lr_clf_title.fit(X_train_title, y_train_title)\n",
    "lr_clf_title_train_acc = lr_clf_title.score(X_train_title, y_train_title)\n",
    "lr_clf_title_test_acc = lr_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Logistic Regression', 'train_acc'] = lr_clf_title_train_acc\n",
    "results_title_final.loc['Logistic Regression', 'test_acc'] = lr_clf_title_test_acc\n",
    "lr_y_pred_title = lr_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Logistic Regression', 'F1-Weighted'] = fbeta_score(y_test_title, lr_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Logistic Regression', 'F2-Weighted'] = fbeta_score(y_test_title, lr_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "gnb_clf_title = sklearn.base.clone(gnb_clf_title)\n",
    "gnb_clf_title.fit(X_train_title, y_train_title)\n",
    "gnb_clf_title_train_acc = gnb_clf_title.score(X_train_title, y_train_title)\n",
    "gnb_clf_title_test_acc = gnb_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_clf_title_train_acc\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_clf_title_test_acc\n",
    "gnb_y_pred_title = gnb_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'F1-Weighted'] = fbeta_score(y_test_title, gnb_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Gaussian Naive Bayes', 'F2-Weighted'] = fbeta_score(y_test_title, gnb_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# SVM\n",
    "svm_clf_title = sklearn.base.clone(svm_clf_title)\n",
    "svm_clf_title.fit(X_train_title, y_train_title)\n",
    "svm_clf_title_train_acc = svm_clf_title.score(X_train_title, y_train_title)\n",
    "svm_clf_title_test_acc = svm_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Support Vector Machine', 'train_acc'] = svm_clf_title_train_acc\n",
    "results_title_final.loc['Support Vector Machine', 'test_acc'] = svm_clf_title_test_acc\n",
    "svm_y_pred_title = svm_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Support Vector Machine', 'F1-Weighted'] = fbeta_score(y_test_title, svm_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Support Vector Machine', 'F2-Weighted'] = fbeta_score(y_test_title, svm_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# Random Forest\n",
    "rf_clf_title = sklearn.base.clone(rf_clf_title)\n",
    "rf_clf_title.fit(X_train_title, y_train_title)\n",
    "rf_clf_title_train_acc = rf_clf_title.score(X_train_title, y_train_title)\n",
    "rf_clf_title_test_acc = rf_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['Random Forest', 'train_acc'] = rf_clf_title_train_acc\n",
    "results_title_final.loc['Random Forest', 'test_acc'] = rf_clf_title_test_acc\n",
    "rf_y_pred_title = rf_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['Random Forest', 'F1-Weighted'] = fbeta_score(y_test_title, rf_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['Random Forest', 'F2-Weighted'] = fbeta_score(y_test_title, rf_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "# XGBoost\n",
    "xgboost_clf_title = sklearn.base.clone(xgboost_clf_title)\n",
    "xgboost_clf_title.fit(X_train_title, y_train_title)\n",
    "xgboost_clf_title_train_acc = xgboost_clf_title.score(X_train_title, y_train_title)\n",
    "xgboost_clf_title_test_acc = xgboost_clf_title.score(X_test_title, y_test_title)\n",
    "results_title_final.loc['XGBoost', 'train_acc'] = xgboost_clf_title_train_acc\n",
    "results_title_final.loc['XGBoost', 'test_acc'] = xgboost_clf_title_test_acc\n",
    "xgboost_y_pred_title = xgboost_clf_title.predict(X_test_title)\n",
    "results_title_final.loc['XGBoost', 'F1-Weighted'] = fbeta_score(y_test_title, xgboost_y_pred_title, beta=1, average=\"weighted\")\n",
    "results_title_final.loc['XGBoost', 'F2-Weighted'] = fbeta_score(y_test_title, xgboost_y_pred_title, beta=2, average=\"weighted\")\n",
    "\n",
    "results_title_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65187ce9",
   "metadata": {},
   "source": [
    "# 5. All Text - Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_final = pd.DataFrame(index=['Logistic Regression', 'Gaussian Naive Bayes', 'Support Vector Machine', 'Random Forest', 'XGBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_clf = sklearn.base.clone(lr_clf)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_all_train_acc = lr_clf.score(X_train, y_train)\n",
    "lr_all_test_acc = lr_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Logistic Regression', 'train_acc'] = lr_all_train_acc\n",
    "results_all_final.loc['Logistic Regression', 'test_acc'] = lr_all_test_acc\n",
    "lr_y_pred = lr_clf.predict(X_test)\n",
    "results_all_final.loc['Logistic Regression', 'F1-Weighted'] = fbeta_score(y_test, lr_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Logistic Regression', 'F2-Weighted'] = fbeta_score(y_test, lr_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# Naive Bayes\n",
    "gnb_clf = sklearn.base.clone(gnb_clf)\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_all_train_acc = gnb_clf.score(X_train, y_train)\n",
    "gnb_all_test_acc = gnb_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'train_acc'] = gnb_all_train_acc\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'test_acc'] = gnb_all_test_acc\n",
    "gnb_y_pred = gnb_clf.predict(X_test)\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'F1-Weighted'] = fbeta_score(y_test, gnb_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Gaussian Naive Bayes', 'F2-Weighted'] = fbeta_score(y_test, gnb_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# SVM\n",
    "svm_clf = sklearn.base.clone(svm_clf)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_all_train_acc = svm_clf.score(X_train, y_train)\n",
    "svm_all_test_acc = svm_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Support Vector Machine', 'train_acc'] = svm_all_train_acc\n",
    "results_all_final.loc['Support Vector Machine', 'test_acc'] = svm_all_test_acc\n",
    "svm_y_pred = svm_clf.predict(X_test)\n",
    "results_all_final.loc['Support Vector Machine', 'F1-Weighted'] = fbeta_score(y_test, svm_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Support Vector Machine', 'F2-Weighted'] = fbeta_score(y_test, svm_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = sklearn.base.clone(rf_clf)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_all_train_acc = rf_clf.score(X_train, y_train)\n",
    "rf_all_test_acc = rf_clf.score(X_test, y_test)\n",
    "results_all_final.loc['Random Forest', 'train_acc'] = rf_all_train_acc\n",
    "results_all_final.loc['Random Forest', 'test_acc'] = rf_all_test_acc\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "results_all_final.loc['Random Forest', 'F1-Weighted'] = fbeta_score(y_test, rf_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['Random Forest', 'F2-Weighted'] = fbeta_score(y_test, rf_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "# XGBoost\n",
    "xgboost_clf = sklearn.base.clone(xgboost_clf)\n",
    "xgboost_clf.fit(X_train, y_train)\n",
    "xgboost_all_train_acc = xgboost_clf.score(X_train, y_train)\n",
    "xgboost_all_test_acc = xgboost_clf.score(X_test, y_test)\n",
    "results_all_final.loc['XGBoost', 'train_acc'] = xgboost_all_train_acc\n",
    "results_all_final.loc['XGBoost', 'test_acc'] = xgboost_all_test_acc\n",
    "xgboost_y_pred = xgboost_clf.predict(X_test)\n",
    "results_all_final.loc['XGBoost', 'F1-Weighted'] = fbeta_score(y_test, xgboost_y_pred, beta=1, average=\"weighted\")\n",
    "results_all_final.loc['XGBoost', 'F2-Weighted'] = fbeta_score(y_test, xgboost_y_pred, beta=2, average=\"weighted\")\n",
    "\n",
    "results_all_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabab621",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_title_style = results_title_final.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Title Only\")\n",
    "results_all_text_style = results_all_final.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Title & Text\")\n",
    "\n",
    "display_html(results_title_style._repr_html_() + results_all_text_style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efa73a",
   "metadata": {},
   "source": [
    "# 6. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac95266",
   "metadata": {},
   "source": [
    "## 6.1 All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5ac1991",
   "metadata": {
    "id": "ca6bdbc9"
   },
   "outputs": [],
   "source": [
    "X = news['all_text']\n",
    "y = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c173d9",
   "metadata": {
    "id": "5df3c627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: all_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a774c7",
   "metadata": {},
   "source": [
    "### 6.1.1 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d200fa7",
   "metadata": {
    "id": "67a86a1e"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8af0c",
   "metadata": {},
   "source": [
    "### 6.1.2 Transforming All Text to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970d278e",
   "metadata": {
    "id": "DKLXJF36ixTI"
   },
   "outputs": [],
   "source": [
    "vectorization = TfidfVectorizer()\n",
    "X_train_vec = vectorization.fit_transform(X_train)\n",
    "X_test_vec = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b884a7b",
   "metadata": {},
   "source": [
    "### 6.1.3 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c76f268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc26b4",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "110e0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_vec, y_train)\n",
    "LR_y_pred = LR.predict(X_test_vec)\n",
    "nlp_results['LR'] = [LR.score(X_train_vec, y_train), LR.score(X_test_vec, y_test),\n",
    "                    fbeta_score(y_test, LR_y_pred, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test, LR_y_pred, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76cbd1",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8107204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB().fit(X_train_vec, y_train)\n",
    "NB_y_pred = NB.predict(X_test_vec)\n",
    "nlp_results['NB'] = [NB.score(X_train_vec, y_train), NB.score(X_test_vec, y_test),\n",
    "                    fbeta_score(y_test, NB_y_pred, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test, NB_y_pred, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2cab1",
   "metadata": {},
   "source": [
    "#### 6.1.3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830ef8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM.fit(X_train_vec, y_train)\n",
    "SVM_y_pred = SVM.predict(X_test_vec)\n",
    "nlp_results['SVM'] = [SVM.score(X_train_vec, y_train), SVM.score(X_test_vec, y_test),\n",
    "                    fbeta_score(y_test, SVM_y_pred, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test, SVM_y_pred, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed00b9d",
   "metadata": {},
   "source": [
    "#### 6.1.3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96cba833",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=1)\n",
    "RFC.fit(X_train_vec, y_train)\n",
    "RFC_y_pred = RFC.predict(X_test_vec)\n",
    "nlp_results['RFC'] = [RFC.score(X_train_vec, y_train), RFC.score(X_test_vec, y_test),\n",
    "                    fbeta_score(y_test, RFC_y_pred, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test, RFC_y_pred, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d311af",
   "metadata": {},
   "source": [
    "#### 6.1.3.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47324f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(random_state=1)\n",
    "XGB.fit(X_train_vec, y_train)\n",
    "XGB_y_pred = XGB.predict(X_test_vec)\n",
    "nlp_results['XGB'] = [XGB.score(X_train_vec, y_train), XGB.score(X_test_vec, y_test),\n",
    "                    fbeta_score(y_test, XGB_y_pred, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test, XGB_y_pred, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68bfcd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9884563150746944, 0.9811174340403518, 0.9811019939867537, 0.9810939676000798], 'NB': [0.9457737825777662, 0.9372736678737713, 0.9370971268692613, 0.9370618041501064], 'SVM': [0.99899760719136, 0.987325400931195, 0.9873183778800231, 0.9873141399806672], 'RFC': [1.0, 0.9714174857734093, 0.9713774371610956, 0.9713564636696664], 'XGB': [1.0, 0.987842731505432, 0.9878378375150025, 0.9878361546355087]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa00d6",
   "metadata": {},
   "source": [
    "### 6.1.4 Storing All Test TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2cd9bdc",
   "metadata": {
    "id": "c8833b85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.981117</td>\n",
       "      <td>0.981102</td>\n",
       "      <td>0.981094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.945774</td>\n",
       "      <td>0.937274</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.937062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.987325</td>\n",
       "      <td>0.987318</td>\n",
       "      <td>0.987314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971417</td>\n",
       "      <td>0.971377</td>\n",
       "      <td>0.971356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987843</td>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.987836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc  F1-Weighted  F2-Weighted\n",
       "Logistic Regression       0.988456  0.981117     0.981102     0.981094\n",
       "Multinomial Naive Bayes   0.945774  0.937274     0.937097     0.937062\n",
       "Support Vector Machine    0.998998  0.987325     0.987318     0.987314\n",
       "Random Forest             1.000000  0.971417     0.971377     0.971356\n",
       "XGBoost                   1.000000  0.987843     0.987838     0.987836"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_results_all_text = pd.DataFrame()\n",
    "\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'train_acc'] = nlp_results['LR'][0]\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'test_acc'] = nlp_results['LR'][1]\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'F1-Weighted'] = nlp_results['LR'][2]\n",
    "tfidf_results_all_text.loc['Logistic Regression', 'F2-Weighted'] = nlp_results['LR'][3]\n",
    "\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results['NB'][0]\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results['NB'][1]\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'F1-Weighted'] = nlp_results['NB'][2]\n",
    "tfidf_results_all_text.loc['Multinomial Naive Bayes', 'F2-Weighted'] = nlp_results['NB'][3]\n",
    "\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'train_acc'] = nlp_results['SVM'][0]\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'test_acc'] = nlp_results['SVM'][1]\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'F1-Weighted'] = nlp_results['SVM'][2]\n",
    "tfidf_results_all_text.loc['Support Vector Machine', 'F2-Weighted'] = nlp_results['SVM'][3]\n",
    "\n",
    "\n",
    "tfidf_results_all_text.loc['Random Forest', 'train_acc'] = nlp_results['RFC'][0]\n",
    "tfidf_results_all_text.loc['Random Forest', 'test_acc'] = nlp_results['RFC'][1]\n",
    "tfidf_results_all_text.loc['Random Forest', 'F1-Weighted'] = nlp_results['RFC'][2]\n",
    "tfidf_results_all_text.loc['Random Forest', 'F2-Weighted'] = nlp_results['RFC'][3]\n",
    "\n",
    "tfidf_results_all_text.loc['XGBoost', 'train_acc'] = nlp_results['XGB'][0]\n",
    "tfidf_results_all_text.loc['XGBoost', 'test_acc'] = nlp_results['XGB'][1]\n",
    "tfidf_results_all_text.loc['XGBoost', 'F1-Weighted'] = nlp_results['XGB'][2]\n",
    "tfidf_results_all_text.loc['XGBoost', 'F2-Weighted'] = nlp_results['XGB'][3]\n",
    "tfidf_results_all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40ce20",
   "metadata": {
    "id": "c4ed466d"
   },
   "source": [
    "## 6.2 Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a671788",
   "metadata": {
    "id": "c291759a"
   },
   "outputs": [],
   "source": [
    "X2 = news['title']\n",
    "y2 = news['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f3bc99e",
   "metadata": {
    "id": "c7d9e9e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Donald Trump Sends Out Embarrassing New Year’...\n",
       "1     Drunk Bragging Trump Staffer Started Russian ...\n",
       "2     Sheriff David Clarke Becomes An Internet Joke...\n",
       "3     Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4     Pope Francis Just Called Out Donald Trump Dur...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922f25f",
   "metadata": {},
   "source": [
    "### 6.2.1 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd76162f",
   "metadata": {
    "id": "cefe6309"
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, shuffle = True, random_state = 1) #20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1e865",
   "metadata": {},
   "source": [
    "### 6.2.2 Transforming Title to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61db8252",
   "metadata": {
    "id": "Z2WUUtNmjd3w"
   },
   "outputs": [],
   "source": [
    "# Converting text to vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorization2 = TfidfVectorizer()\n",
    "X_train_vec2 = vectorization2.fit_transform(X_train2)\n",
    "X_test_vec2 = vectorization2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077fc53",
   "metadata": {},
   "source": [
    "### 6.2.3 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78dccdfc",
   "metadata": {
    "id": "2gUk5E5yhKxc"
   },
   "outputs": [],
   "source": [
    "nlp_results_title = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a6a17",
   "metadata": {},
   "source": [
    "#### 6.2.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "165011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = LogisticRegression()\n",
    "LR2.fit(X_train_vec2, y_train2)\n",
    "LR_y_pred2 = LR2.predict(X_test_vec2)\n",
    "nlp_results_title['LR'] = [LR2.score(X_train_vec2, y_train2), LR2.score(X_test_vec2, y_test2),\n",
    "                    fbeta_score(y_test2, LR_y_pred2, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test2, LR_y_pred2, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf862d3",
   "metadata": {},
   "source": [
    "#### 6.2.3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d760596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB2 = MultinomialNB().fit(X_train_vec2, y_train2)\n",
    "NB_y_pred2 = NB2.predict(X_test_vec2)\n",
    "nlp_results_title['NB'] = [NB2.score(X_train_vec2, y_train2), NB2.score(X_test_vec2, y_test2),\n",
    "                    fbeta_score(y_test2, NB_y_pred2, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test2, NB_y_pred2, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a16702",
   "metadata": {},
   "source": [
    "#### 6.2.3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26f27826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM2 = SVC(kernel='rbf', gamma='scale', random_state=1)\n",
    "SVM2.fit(X_train_vec2, y_train2)\n",
    "SVM_y_pred2 = SVM2.predict(X_test_vec2)\n",
    "nlp_results_title['SVM'] = [SVM2.score(X_train_vec2, y_train2), SVM2.score(X_test_vec2, y_test2),\n",
    "                    fbeta_score(y_test2, SVM_y_pred2, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test2, SVM_y_pred2, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c23bc",
   "metadata": {},
   "source": [
    "#### 6.2.3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1546a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC2 = RandomForestClassifier(random_state=1)\n",
    "RFC2.fit(X_train_vec2, y_train2)\n",
    "RFC_y_pred2 = RFC2.predict(X_test_vec2)\n",
    "nlp_results_title['RFC'] = [RFC2.score(X_train_vec2, y_train2), RFC2.score(X_test_vec2, y_test2),\n",
    "                    fbeta_score(y_test2, RFC_y_pred2, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test2, RFC_y_pred2, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8ccbb",
   "metadata": {},
   "source": [
    "#### 6.2.3.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40cbf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2 = XGBClassifier(random_state=1)\n",
    "XGB2.fit(X_train_vec2, y_train2)\n",
    "XGB_y_pred2 = XGB2.predict(X_test_vec2)\n",
    "nlp_results_title['XGB'] = [XGB2.score(X_train_vec2, y_train2), XGB2.score(X_test_vec2, y_test2),\n",
    "                    fbeta_score(y_test2, XGB_y_pred2, beta=1, average=\"weighted\"),\n",
    "                    fbeta_score(y_test2, XGB_y_pred2, beta=2, average=\"weighted\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8feef003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR': [0.9650779279570588, 0.9443869632695292, 0.9442876674127253, 0.9442806885418648], 'NB': [0.957964172540904, 0.9408949818934299, 0.9409097512289684, 0.9408988786736209], 'SVM': [0.9959904287654401, 0.9511122607346094, 0.9510614919276704, 0.9510660913890966], 'RFC': [1.0, 0.9425763062596999, 0.942421848801372, 0.9423825818642654], 'XGB': [0.9545366358403932, 0.9335230212105535, 0.9332233589316983, 0.9331069121706412]}\n"
     ]
    }
   ],
   "source": [
    "print(nlp_results_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1102476",
   "metadata": {},
   "source": [
    "### 6.2.4 Storing Title TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0960c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>F2-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.965078</td>\n",
       "      <td>0.944387</td>\n",
       "      <td>0.944288</td>\n",
       "      <td>0.944281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.940895</td>\n",
       "      <td>0.940910</td>\n",
       "      <td>0.940899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.951112</td>\n",
       "      <td>0.951061</td>\n",
       "      <td>0.951066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.942422</td>\n",
       "      <td>0.942383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.954537</td>\n",
       "      <td>0.933523</td>\n",
       "      <td>0.933223</td>\n",
       "      <td>0.933107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_acc  test_acc  F1-Weighted  F2-Weighted\n",
       "Logistic Regression       0.965078  0.944387     0.944288     0.944281\n",
       "Multinomial Naive Bayes   0.957964  0.940895     0.940910     0.940899\n",
       "Support Vector Machine    0.995990  0.951112     0.951061     0.951066\n",
       "Random Forest             1.000000  0.942576     0.942422     0.942383\n",
       "XGBoost                   0.954537  0.933523     0.933223     0.933107"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results_title = pd.DataFrame()\n",
    "\n",
    "tfidf_results_title.loc['Logistic Regression', 'train_acc'] = nlp_results_title['LR'][0]\n",
    "tfidf_results_title.loc['Logistic Regression', 'test_acc'] = nlp_results_title['LR'][1]\n",
    "tfidf_results_title.loc['Logistic Regression', 'F1-Weighted'] = nlp_results_title['LR'][2]\n",
    "tfidf_results_title.loc['Logistic Regression', 'F2-Weighted'] = nlp_results_title['LR'][3]\n",
    "\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'train_acc'] = nlp_results_title['NB'][0]\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'test_acc'] = nlp_results_title['NB'][1]\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'F1-Weighted'] = nlp_results_title['NB'][2]\n",
    "tfidf_results_title.loc['Multinomial Naive Bayes', 'F2-Weighted'] = nlp_results_title['NB'][3]\n",
    "\n",
    "tfidf_results_title.loc['Support Vector Machine', 'train_acc'] = nlp_results_title['SVM'][0]\n",
    "tfidf_results_title.loc['Support Vector Machine', 'test_acc'] = nlp_results_title['SVM'][1]\n",
    "tfidf_results_title.loc['Support Vector Machine', 'F1-Weighted'] = nlp_results_title['SVM'][2]\n",
    "tfidf_results_title.loc['Support Vector Machine', 'F2-Weighted'] = nlp_results_title['SVM'][3]\n",
    "\n",
    "\n",
    "tfidf_results_title.loc['Random Forest', 'train_acc'] = nlp_results_title['RFC'][0]\n",
    "tfidf_results_title.loc['Random Forest', 'test_acc'] = nlp_results_title['RFC'][1]\n",
    "tfidf_results_title.loc['Random Forest', 'F1-Weighted'] = nlp_results_title['RFC'][2]\n",
    "tfidf_results_title.loc['Random Forest', 'F2-Weighted'] = nlp_results_title['RFC'][3]\n",
    "\n",
    "tfidf_results_title.loc['XGBoost', 'train_acc'] = nlp_results_title['XGB'][0]\n",
    "tfidf_results_title.loc['XGBoost', 'test_acc'] = nlp_results_title['XGB'][1]\n",
    "tfidf_results_title.loc['XGBoost', 'F1-Weighted'] = nlp_results_title['XGB'][2]\n",
    "tfidf_results_title.loc['XGBoost', 'F2-Weighted'] = nlp_results_title['XGB'][3]\n",
    "tfidf_results_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbed3e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {'max_depth': [3, 6, 10, 15],\n",
    "      'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "      'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "      'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "      }\n",
    "search = RandomizedSearchCV(estimator=XGB,\n",
    "                         param_distributions=params,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=2, random_state=1)\n",
    "search.fit(X_train_vec, y_train)\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a206ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_tuned = XGBClassifier(**search.best_params_, random_state=1)\n",
    "XGB_tuned.fit(X_train_vec, y_train)\n",
    "nlp_results['XGB Tuned'] = [XGB_tuned.score(X_train_vec, y_train), XGB_tuned.score(X_test_vec, y_test)]\n",
    "print(\"Training Accuracy:\", nlp_results['XGB Tuned'][0])\n",
    "print(\"Testing Accuracy:\", nlp_results['XGB Tuned'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dff928",
   "metadata": {},
   "source": [
    "Accuracy went up by a marginal 0.02% after tuning hyperparameters. Hence, hyperparameter tuning may not be worth the efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dac4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = XGB.predict_proba(X_test_vec)[:,1]\n",
    "y_pred_prob2 = XGB_tuned.predict_proba(X_test_vec)[:,1]\n",
    "print('XGB ROC_AUC:', metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "print('XGB Tuned ROC_AUC:', metrics.roc_auc_score(y_test, y_pred_prob2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a6d3a1c9702cbdea61a84eb923333e247e4db67d8a1f6fe21a7310eabf978f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
